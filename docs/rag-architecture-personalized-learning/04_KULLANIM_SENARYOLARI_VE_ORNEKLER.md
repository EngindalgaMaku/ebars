# KullanÄ±m SenaryolarÄ± ve Ã–rnekler

## 1. Temel RAG Sorgusu Senaryosu

### 1.1. Senaryo: Basit Bilgi Sorgusu

**KullanÄ±cÄ± Sorusu:**
```
"RAG nedir?"
```

**Sistem Ä°ÅŸlemi:**
1. Query embedding oluÅŸturulur
2. Vector store'da similarity search yapÄ±lÄ±r
3. Top-5 dokÃ¼man getirilir
4. Context oluÅŸturulur
5. LLM ile cevap Ã¼retilir

**Ã–rnek Cevap:**
```
RAG (Retrieval-Augmented Generation), bÃ¼yÃ¼k dil modellerinin 
bilgi eriÅŸim yeteneklerini artÄ±rmak iÃ§in kullanÄ±lan bir 
yaklaÅŸÄ±mdÄ±r. Bu yÃ¶ntem, modelin kendi eÄŸitim verilerine 
baÄŸÄ±mlÄ± kalmadan, harici bir bilgi kaynaÄŸÄ±ndan (vektÃ¶r 
veritabanÄ±) ilgili bilgileri Ã§ekerek daha doÄŸru ve gÃ¼ncel 
cevaplar Ã¼retmesini saÄŸlar.
```

**Kaynaklar:**
- DokÃ¼man: "Yapay Zeka Temelleri.pdf", Sayfa 15
- Benzerlik Skoru: 0.87

### 1.2. Senaryo: KarmaÅŸÄ±k Kavramsal Soru

**KullanÄ±cÄ± Sorusu:**
```
"RAG sistemlerinde chunking stratejileri neden Ã¶nemlidir 
ve hangi faktÃ¶rler chunk boyutunu etkiler?"
```

**Sistem Ä°ÅŸlemi:**
1. Multi-query generation (3 alternatif sorgu)
2. Her sorgu iÃ§in retrieval
3. Result deduplication
4. Reranking uygulanÄ±r
5. GeniÅŸ context ile cevap Ã¼retilir

**Ã–rnek Cevap:**
```
Chunking stratejileri, RAG sistemlerinin performansÄ±nÄ± 
doÄŸrudan etkiler Ã§Ã¼nkÃ¼:

1. **Bilgi BÃ¼tÃ¼nlÃ¼ÄŸÃ¼**: Chunk boyutu, bir kavramÄ±n tam 
   olarak anlaÅŸÄ±lmasÄ± iÃ§in yeterli baÄŸlamÄ± saÄŸlamalÄ±dÄ±r.

2. **Retrieval Kalitesi**: Ã‡ok kÃ¼Ã§Ã¼k chunk'lar baÄŸlam 
   kaybÄ±na, Ã§ok bÃ¼yÃ¼k chunk'lar ise gÃ¼rÃ¼ltÃ¼ye neden olur.

3. **Chunk Boyutunu Etkileyen FaktÃ¶rler**:
   - DokÃ¼man tÃ¼rÃ¼ (teknik, akademik, genel)
   - Dil yapÄ±sÄ± (TÃ¼rkÃ§e iÃ§in morfolojik analiz gerekli)
   - Embedding model kapasitesi
   - LLM context window boyutu
```

## 2. KiÅŸiselleÅŸtirilmiÅŸ EÄŸitim Senaryosu

### 2.1. Senaryo: Yeni BaÅŸlayan Ã–ÄŸrenci

**Ã–ÄŸrenci Profili:**
- `average_understanding`: 2.5 (DÃ¼ÅŸÃ¼k)
- `total_interactions`: 5
- `preferred_difficulty_level`: beginner

**Soru:**
```
"Embedding nedir?"
```

**Sistem Ä°ÅŸlemi:**
1. **ZPD Hesaplama**: `beginner` seviyesi tespit edilir
2. **Bloom Tespiti**: `remember` seviyesi (tanÄ±m sorusu)
3. **Cognitive Load**: DÃ¼ÅŸÃ¼k (basit soru)
4. **Personalization**: BasitleÅŸtirilmiÅŸ cevap Ã¼retilir

**KiÅŸiselleÅŸtirilmiÅŸ Cevap:**
```
**Embedding**, metinleri sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rme 
iÅŸlemidir. BasitÃ§e sÃ¶ylemek gerekirse:

ğŸ“ **Basit AÃ§Ä±klama:**
Embedding, kelimeleri veya cÃ¼mleleri bilgisayarÄ±n 
anlayabileceÄŸi sayÄ± dizilerine Ã§evirir. Ã–rneÄŸin, "kedi" 
kelimesi [0.2, 0.5, -0.1, ...] gibi bir sayÄ± dizisine 
dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.

ğŸ’¡ **GÃ¼nlÃ¼k Hayat Ã–rneÄŸi:**
TÄ±pkÄ± bir sÃ¶zlÃ¼kte kelimelerin anlamlarÄ±nÄ±n yazÄ±lmasÄ± 
gibi, embedding'ler de kelimelerin "anlamlarÄ±nÄ±" sayÄ±sal 
olarak temsil eder. Benzer anlamlÄ± kelimeler (Ã¶rneÄŸin 
"kedi" ve "kÃ¶pek") birbirine yakÄ±n sayÄ± dizilerine 
sahiptir.

ğŸ”‘ **Anahtar Kelimeler:**
- **Embedding**: SayÄ±sal temsil
- **VektÃ¶r**: SayÄ± dizisi
- **Benzerlik**: YakÄ±n sayÄ±lar = benzer anlamlar
```

**Pedagojik Bilgiler:**
- ZPD: `beginner` â†’ `elementary` (Ã¶nerilen)
- Bloom: `remember` (Seviye 1)
- Cognitive Load: 0.35 (DÃ¼ÅŸÃ¼k)

### 2.2. Senaryo: Ä°leri Seviye Ã–ÄŸrenci

**Ã–ÄŸrenci Profili:**
- `average_understanding`: 4.5 (YÃ¼ksek)
- `total_interactions`: 50
- `preferred_difficulty_level`: advanced

**Soru:**
```
"RAG sistemlerinde reranking stratejilerinin cross-encoder 
modelleri ile uygulanmasÄ± nasÄ±l Ã§alÄ±ÅŸÄ±r ve bi-encoder 
yaklaÅŸÄ±mlarÄ±ndan farkÄ± nedir?"
```

**Sistem Ä°ÅŸlemi:**
1. **ZPD Hesaplama**: `advanced` seviyesi
2. **Bloom Tespiti**: `analyze` seviyesi (karÅŸÄ±laÅŸtÄ±rma)
3. **Cognitive Load**: Orta (karmaÅŸÄ±k soru)
4. **Personalization**: DetaylÄ±, teknik cevap

**KiÅŸiselleÅŸtirilmiÅŸ Cevap:**
```
RAG sistemlerinde reranking, cross-encoder modelleri 
kullanÄ±larak query-document Ã§iftlerinin birlikte 
encode edilmesi prensibine dayanÄ±r. Bu yaklaÅŸÄ±m, 
bi-encoder modellerinden temel olarak ÅŸu farklara sahiptir:

**Cross-Encoder YaklaÅŸÄ±mÄ±:**
1. Query ve document aynÄ± anda model giriÅŸine verilir
2. Model, Ã§iftin birlikte temsilini Ã¶ÄŸrenir
3. Daha yÃ¼ksek doÄŸruluk, ancak daha yavaÅŸ inference
4. Her query-document Ã§ifti iÃ§in ayrÄ± forward pass gerekir

**Bi-Encoder YaklaÅŸÄ±mÄ±:**
1. Query ve document ayrÄ± ayrÄ± encode edilir
2. Cosine similarity ile skorlama yapÄ±lÄ±r
3. Daha hÄ±zlÄ± inference (batch processing mÃ¼mkÃ¼n)
4. Daha dÃ¼ÅŸÃ¼k doÄŸruluk, ancak Ã¶lÃ§eklenebilir

**Pratik Uygulama:**
RAG pipeline'larÄ±nda genellikle iki aÅŸamalÄ± yaklaÅŸÄ±m 
kullanÄ±lÄ±r:
- Ä°lk aÅŸama: Bi-encoder ile geniÅŸ retrieval (top-100)
- Ä°kinci aÅŸama: Cross-encoder ile reranking (top-10)
```

**Pedagojik Bilgiler:**
- ZPD: `advanced` â†’ `expert` (Ã¶nerilen)
- Bloom: `analyze` (Seviye 4)
- Cognitive Load: 0.65 (Orta)

## 3. Hybrid RAG Senaryosu

### 3.1. Senaryo: QA Pair EÅŸleÅŸmesi

**Soru:**
```
"Machine Learning nedir?"
```

**Sistem Ä°ÅŸlemi:**
1. Topic classification: "Machine Learning" konusu tespit edilir
2. QA pair matching: Benzerlik skoru 0.92 (yÃ¼ksek)
3. **Direct QA Match**: QA pair'den direkt cevap dÃ¶ndÃ¼rÃ¼lÃ¼r
4. KB summary ile zenginleÅŸtirilir

**Cevap:**
```
Machine Learning, bilgisayarlarÄ±n verilerden Ã¶ÄŸrenerek 
gÃ¶revleri yerine getirmesini saÄŸlayan yapay zeka 
dalÄ±dÄ±r. AÃ§Ä±k programlama talimatlarÄ± yerine, algoritmalar 
veri setlerinden desenler ve iliÅŸkiler Ã¶ÄŸrenir.

ğŸ’¡ **Ek Bilgi:**
Machine Learning, Ã¼Ã§ ana kategoride incelenir: Supervised 
Learning (denetimli Ã¶ÄŸrenme), Unsupervised Learning 
(denetimsiz Ã¶ÄŸrenme) ve Reinforcement Learning 
(pekiÅŸtirmeli Ã¶ÄŸrenme). Her yaklaÅŸÄ±m, farklÄ± problem 
tÃ¼rleri iÃ§in optimize edilmiÅŸtir.
```

**Retrieval Stratejisi:** `direct_qa_match`
**Confidence:** `high`
**Sources Used:** 
- QA Pair: 1
- Knowledge Base: 1
- Chunks: 0

### 3.2. Senaryo: Hybrid Retrieval

**Soru:**
```
"Derin Ã¶ÄŸrenme modellerinde overfitting nasÄ±l Ã¶nlenir?"
```

**Sistem Ä°ÅŸlemi:**
1. Topic classification: "Deep Learning" konusu
2. Chunk retrieval: 8 chunk getirilir
3. KB retrieval: 2 KB Ã¶ÄŸesi getirilir
4. QA matching: Benzerlik dÃ¼ÅŸÃ¼k (<0.90), QA kullanÄ±lmaz
5. Reranking: Cross-encoder ile sÄ±ralama
6. Merged results: TÃ¼m kaynaklar birleÅŸtirilir
7. Context building ve LLM generation

**Cevap:**
```
Overfitting'i Ã¶nlemek iÃ§in ÅŸu teknikler kullanÄ±lÄ±r:

1. **Regularization**: L1/L2 regularization ile model 
   karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± kontrol etme

2. **Dropout**: EÄŸitim sÄ±rasÄ±nda rastgele nÃ¶ronlarÄ± 
   devre dÄ±ÅŸÄ± bÄ±rakma

3. **Early Stopping**: Validation loss artmaya baÅŸladÄ±ÄŸÄ±nda 
   eÄŸitimi durdurma

4. **Data Augmentation**: EÄŸitim verisini Ã§eÅŸitlendirme

5. **Cross-Validation**: Model performansÄ±nÄ± doÄŸrulama
```

**Retrieval Stratejisi:** `hybrid_kb_rag`
**Confidence:** `medium`
**Sources Used:**
- Chunks: 5
- Knowledge Base: 2
- QA Pairs: 0

## 4. Adaptive Query Senaryosu

### 4.1. Senaryo: Tam Pipeline

**Soru:**
```
"Gradient descent algoritmasÄ± nasÄ±l Ã§alÄ±ÅŸÄ±r?"
```

**Sistem Ä°ÅŸlemi:**

**1. Student Profile Loading:**
- User: student_123
- Session: session_456
- Profile: intermediate level, 25 interactions

**2. CACS Document Scoring:**
- 10 RAG dokÃ¼manÄ± skorlanÄ±r
- Personal score, global score, context score hesaplanÄ±r
- Top-3 dokÃ¼man seÃ§ilir

**3. Pedagogical Analysis:**
- **ZPD**: `intermediate` â†’ `intermediate` (optimal)
- **Bloom**: `understand` (Seviye 2)
- **Cognitive Load**: 0.55 (Orta, basitleÅŸtirme gerekmez)

**4. Personalized Response Generation:**
- ZPD seviyesine gÃ¶re: Orta detay seviyesi
- Bloom seviyesine gÃ¶re: AÃ§Ä±klayÄ±cÄ± yaklaÅŸÄ±m
- Cognitive load: Normal seviyede tutulur

**5. Interaction Recording:**
- Interaction kaydedilir
- Metadata (ZPD, Bloom, Cognitive Load) saklanÄ±r
- Emoji feedback hazÄ±rlÄ±ÄŸÄ± yapÄ±lÄ±r

**KiÅŸiselleÅŸtirilmiÅŸ Cevap:**
```
Gradient descent, bir optimizasyon algoritmasÄ±dÄ±r ve 
fonksiyonun minimum deÄŸerini bulmak iÃ§in kullanÄ±lÄ±r.

**Ã‡alÄ±ÅŸma Prensibi:**
1. BaÅŸlangÄ±Ã§ noktasÄ± seÃ§ilir (rastgele aÄŸÄ±rlÄ±klar)
2. Gradient (tÃ¼rev) hesaplanÄ±r - fonksiyonun en dik 
   yokuÅŸ yÃ¶nÃ¼
3. Gradient'in tersi yÃ¶nÃ¼nde adÄ±m atÄ±lÄ±r
4. Bu iÅŸlem minimum noktaya ulaÅŸana kadar tekrarlanÄ±r

**GÃ¼nlÃ¼k Hayat Benzetmesi:**
Bir daÄŸda en alÃ§ak noktayÄ± bulmak istediÄŸinizi dÃ¼ÅŸÃ¼nÃ¼n. 
Her adÄ±mda, en dik yokuÅŸ yÃ¶nÃ¼nÃ¼n tersine yÃ¼rÃ¼rsÃ¼nÃ¼z. 
Bu, sizi en alÃ§ak noktaya gÃ¶tÃ¼rÃ¼r.

**Ã–nemli Parametreler:**
- **Learning Rate**: Her adÄ±mda ne kadar ilerleyeceÄŸiniz
- **Iterations**: KaÃ§ adÄ±m atacaÄŸÄ±nÄ±z
- **Convergence**: Minimum noktaya ne zaman ulaÅŸtÄ±ÄŸÄ±nÄ±z
```

**Response Metadata:**
- `interaction_id`: 12345
- `cacs_applied`: true
- `zpd_level`: intermediate
- `bloom_level`: understand
- `cognitive_load`: 0.55

## 5. Feedback Loop Senaryosu

### 5.1. Senaryo: Emoji Feedback

**EtkileÅŸim:**
- Soru: "RAG nedir?"
- Cevap: [KiÅŸiselleÅŸtirilmiÅŸ cevap]
- Ã–ÄŸrenci Feedback: ğŸ˜Š (Pozitif)

**Sistem Ä°ÅŸlemi:**
1. Emoji feedback kaydedilir
2. Understanding level gÃ¼ncellenir (varsayÄ±lan: 4.0)
3. Profile gÃ¼ncellenir:
   - `average_satisfaction`: Artar
   - `total_feedback_count`: +1
4. ZPD hesaplamasÄ± iÃ§in veri toplanÄ±r

### 5.2. Senaryo: Uncertainty Sampling

**Sistem Belirsizlik Tespiti:**
- Retriever skorlarÄ±: [0.65, 0.62, 0.58] (dÃ¼ÅŸÃ¼k)
- Skorlar arasÄ± fark: 0.07 (dÃ¼ÅŸÃ¼k marj)
- **Uncertainty Score**: 0.72 (yÃ¼ksek)

**Sistem DavranÄ±ÅŸÄ±:**
- Proaktif geri bildirim istenir
- DetaylÄ± feedback formu gÃ¶sterilir
- Understanding level ve satisfaction score toplanÄ±r

### 5.3. Senaryo: Feedback Analysis

**Periyodik Analiz (24 saatte bir):**

**Analiz SonuÃ§larÄ±:**
- En dÃ¼ÅŸÃ¼k puanlÄ± sorgular:
  1. "RAG vs Fine-tuning" (avg: 2.5)
  2. "Chunking strategies" (avg: 2.8)

- En sorunlu konular:
  - "Advanced RAG techniques"
  - "Model comparison"

**Sistem AyarÄ±:**
- Bu konular iÃ§in daha fazla context saÄŸlanÄ±r
- RAG parametreleri optimize edilir
- KB Ã¶zetleri gÃ¼ncellenir

## 6. Learning Loop Senaryosu

### 6.1. Senaryo: Trend Detection

**7 GÃ¼nlÃ¼k Performans:**
- Ortalama puan: 3.2

**30 GÃ¼nlÃ¼k Performans:**
- Ortalama puan: 4.1

**Trend Analizi:**
- KÄ±sa vadeli < Uzun vadeli %90'Ä±
- **Trend**: `DÃœÅÃœÅTE`
- **Aksiyon**: Sistem parametreleri gÃ¶zden geÃ§irilir

### 6.2. Senaryo: Parameter Optimization

**Feedback Analizi:**
- "Kavramsal" sorgularda Refine chain %20 daha iyi performans
- `chunk_size=1000` optimal gÃ¶rÃ¼nÃ¼yor
- `top_k=5` yeterli

**Optimizasyon:**
- Adaptive Query Router kurallarÄ± gÃ¼ncellenir
- Yeni konfigÃ¼rasyon test edilir
- A/B testing baÅŸlatÄ±lÄ±r

## 7. Edge Cases ve Hata SenaryolarÄ±

### 7.1. Senaryo: Profil BulunamadÄ±

**Durum:**
- Yeni Ã¶ÄŸrenci, profil yok

**Sistem DavranÄ±ÅŸÄ±:**
1. VarsayÄ±lan profil oluÅŸturulur
2. `average_understanding`: 3.0 (orta)
3. ZPD: `intermediate` (varsayÄ±lan)
4. Normal pipeline devam eder

### 7.2. Senaryo: DÃ¼ÅŸÃ¼k Benzerlik Skoru

**Durum:**
- Max similarity score: 0.35
- Threshold: 0.40

**Sistem DavranÄ±ÅŸÄ±:**
1. **Reject**: Cevap Ã¼retilmez
2. Mesaj: "Bu bilgi ders dÃ¶kÃ¼manlarÄ±nda bulunamamÄ±ÅŸtÄ±r."
3. Suggestions: Takip sorularÄ± Ã¶nerilir

### 7.3. Senaryo: LLM Timeout

**Durum:**
- LLM generation 60 saniyeyi aÅŸtÄ±

**Sistem DavranÄ±ÅŸÄ±:**
1. Timeout hatasÄ± yakalanÄ±r
2. Graceful degradation: Hata mesajÄ± dÃ¶ndÃ¼rÃ¼lÃ¼r
3. Original response (eÄŸer varsa) kullanÄ±lÄ±r

## 8. Performans SenaryolarÄ±

### 8.1. Senaryo: Cache Hit

**Ä°lk Sorgu:**
- Query: "RAG nedir?"
- Processing time: 2.5 saniye
- Cache: MISS

**Ä°kinci Sorgu (AynÄ±):**
- Query: "RAG nedir?"
- Processing time: 0.1 saniye
- Cache: HIT

### 8.2. Senaryo: Batch Processing

**Ã‡oklu Sorgu:**
- 5 farklÄ± sorgu aynÄ± anda
- Parallel retrieval
- Batch embedding generation
- Toplam sÃ¼re: 3.2 saniye (sequential: ~12 saniye)

## 9. Integration SenaryolarÄ±

### 9.1. Senaryo: Frontend Integration

**Frontend Request:**
```javascript
POST /api/adaptive-query
{
    "user_id": "student_123",
    "session_id": "session_456",
    "query": "RAG nedir?",
    "rag_documents": [...],
    "rag_response": "..."
}
```

**Backend Response:**
```json
{
    "personalized_response": "...",
    "original_response": "...",
    "interaction_id": 12345,
    "top_documents": [...],
    "cacs_applied": true,
    "pedagogical_context": {...},
    "feedback_emoji_options": ["ğŸ˜Š", "ğŸ‘", "ğŸ˜", "âŒ"],
    "processing_time_ms": 1250,
    "components_active": {...}
}
```

### 9.2. Senaryo: Service-to-Service Communication

**APRAG Service â†’ Model Inference Service:**
```
POST http://model-inference-service:8002/models/generate
{
    "prompt": "...",
    "model": "llama-3.1-8b-instant",
    "max_tokens": 1024,
    "temperature": 0.7
}
```

**Response:**
```json
{
    "response": "...",
    "model": "llama-3.1-8b-instant",
    "tokens_used": 150
}
```

## 10. Ã–zet ve Best Practices

### 10.1. En Ä°yi Uygulamalar

1. **Profil OluÅŸturma**: Ä°lk etkileÅŸimlerde varsayÄ±lan profil kullan
2. **Graceful Degradation**: BileÅŸenler devre dÄ±ÅŸÄ± olsa bile Ã§alÄ±ÅŸ
3. **Error Handling**: TÃ¼m hatalarÄ± yakala ve logla
4. **Performance**: Cache kullan, batch processing yap
5. **Monitoring**: KapsamlÄ± debug bilgileri topla

### 10.2. Ã–neriler

- ZPD seviyesini dÃ¼zenli gÃ¼ncelle
- Feedback loop'u aktif tut
- Parameter optimization'Ä± periyodik Ã§alÄ±ÅŸtÄ±r
- Trend analizini izle
- Cache stratejisini optimize et




