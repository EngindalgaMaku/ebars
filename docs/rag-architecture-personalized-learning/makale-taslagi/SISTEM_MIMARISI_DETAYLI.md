# Sistem Mimarisi: Hibrit RAG TabanlÄ± KiÅŸiselleÅŸtirilmiÅŸ Ã–ÄŸrenme Sistemi

## 1. Genel Mimari BakÄ±ÅŸ

Sistemimiz, **hibrit bilgi eriÅŸimi** yaklaÅŸÄ±mÄ±nÄ± kullanarak Ã¼Ã§ farklÄ± bilgi kaynaÄŸÄ±nÄ± birleÅŸtiren bir RAG (Retrieval-Augmented Generation) mimarisi Ã¼zerine kurulmuÅŸtur. Bu mimari, TÃ¼rk eÄŸitim sistemine Ã¶zgÃ¼ olarak tasarlanmÄ±ÅŸ ve TÃ¼rkÃ§e dil yapÄ±sÄ±na Ã¶zel optimizasyonlar iÃ§ermektedir.

### 1.1. Mimari Prensipler

- **Hibrit Bilgi EriÅŸimi**: Chunks, Knowledge Base ve QA Pairs'Ä± birleÅŸtiren Ã¼Ã§ katmanlÄ± yaklaÅŸÄ±m
- **TÃ¼rkÃ§e Dil DesteÄŸi**: TÃ¼rkÃ§e'nin morfolojik yapÄ±sÄ±na Ã¶zel optimizasyonlar
- **Pedagojik Entegrasyon**: ZPD, Bloom Taksonomisi ve BiliÅŸsel YÃ¼k Teorisi ile zenginleÅŸtirme
- **Performans Optimizasyonu**: Ã–nbellekleme, toplu iÅŸleme ve akÄ±llÄ± yedek mekanizmalarÄ±
- **ModÃ¼ler TasarÄ±m**: Her bileÅŸen baÄŸÄ±msÄ±z olarak geliÅŸtirilebilir ve test edilebilir

### 1.2. Sistem BileÅŸenleri

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              KullanÄ±cÄ± ArayÃ¼zÃ¼ (Frontend)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              API Gateway                                â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚               â”‚               â”‚
      â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  APRAG   â”‚   â”‚ Document â”‚   â”‚   Model      â”‚
â”‚ Service  â”‚   â”‚Processingâ”‚   â”‚  Inference   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚              â”‚                â”‚
     â–¼              â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Hybrid Knowledge Retriever              â”‚
â”‚    â”œâ”€ Chunk Retrieval (Vector Search)       â”‚
â”‚    â”œâ”€ Knowledge Base Retrieval              â”‚
â”‚    â””â”€ QA Pair Matching                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Pedagojik MonitÃ¶rler                     â”‚
â”‚    â”œâ”€ ZPD Calculator                        â”‚
â”‚    â”œâ”€ Bloom Taxonomy Detector               â”‚
â”‚    â””â”€ Cognitive Load Manager                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    CACS (Context-Aware Content Scoring)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Personalization Pipeline                 â”‚
â”‚    â””â”€ LLM-Based Response Generation          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Ã–ÄŸrenci Sorgusunun Ä°ÅŸlenme SÃ¼reci

### 2.1. Genel Ä°ÅŸlem AkÄ±ÅŸÄ±

Bir Ã¶ÄŸrenci sorgusu geldiÄŸinde sistem ÅŸu adÄ±mlarÄ± izler:

```
Ã–ÄŸrenci Sorgusu
    â†“
1. Topic Classification (Konu SÄ±nÄ±flandÄ±rmasÄ±)
   â”œâ”€ Keyword-Based Classification (HÄ±zlÄ±)
   â””â”€ LLM-Based Classification (Gerekirse)
    â†“
2. Paralel Bilgi EriÅŸimi
   â”œâ”€ Chunk Retrieval (VektÃ¶r Arama)
   â”œâ”€ Knowledge Base Retrieval (Konu EÅŸleÅŸtirme)
   â””â”€ QA Pair Matching (Benzerlik Arama)
    â†“
3. Direct Answer KontrolÃ¼
   â”œâ”€ Similarity > 0.90 ise â†’ Direkt Cevap (HÄ±zlÄ± Yol)
   â””â”€ DeÄŸilse â†’ Normal Yol
    â†“
4. SonuÃ§ BirleÅŸtirme (Merging)
   â”œâ”€ Weighted Fusion
   â””â”€ Reranking (Ä°steÄŸe BaÄŸlÄ±)
    â†“
5. Context OluÅŸturma
    â†“
6. LLM ile Cevap Ãœretimi
    â†“
7. KiÅŸiselleÅŸtirme (Pedagojik MonitÃ¶rler)
    â†“
KiÅŸiselleÅŸtirilmiÅŸ Cevap
```

### 2.2. Hybrid RAG Query Endpoint Ä°ÅŸleyiÅŸi

**Endpoint:** `/api/hybrid-rag/query`

**Ä°stek Parametreleri:**
- `query`: Ã–ÄŸrenci sorusu
- `session_id`: Ã–ÄŸrenme oturumu ID'si
- `user_id`: Ã–ÄŸrenci kullanÄ±cÄ± ID'si
- `top_k`: AlÄ±nacak chunk sayÄ±sÄ± (varsayÄ±lan: 10)
- `use_kb`: Knowledge Base kullanÄ±mÄ± (varsayÄ±lan: true)
- `use_qa_pairs`: QA Ã§iftleri kullanÄ±mÄ± (varsayÄ±lan: true)
- `use_crag`: Reranking kullanÄ±mÄ± (varsayÄ±lan: false)

**Ä°ÅŸlem AdÄ±mlarÄ±:**

#### AdÄ±m 1: Session AyarlarÄ±nÄ± YÃ¼kleme
```python
# API Gateway'den session bilgileri alÄ±nÄ±r
session_rag_settings = {
    "model": "llama-3.1-8b-instant",
    "embedding_model": "text-embedding-v4"
}
```

#### AdÄ±m 2: Hybrid Knowledge Retriever BaÅŸlatma
```python
retriever = HybridKnowledgeRetriever(db)
retrieval_result = await retriever.retrieve_for_query(
    query=request.query,
    session_id=request.session_id,
    top_k=retrieval_top_k,
    use_kb=request.use_kb,
    use_qa_pairs=request.use_qa_pairs,
    embedding_model=effective_embedding_model
)
```

#### AdÄ±m 3: Direct Answer KontrolÃ¼
```python
direct_qa = retriever.get_direct_answer_if_available(retrieval_result)

if direct_qa and direct_qa["similarity_score"] > 0.90:
    # HIZLI YOL: Direkt QA pair'den cevap
    # LLM generation'a gerek yok
    answer = direct_qa["answer"]
    if direct_qa.get("explanation"):
        answer += f"\n\nğŸ’¡ {direct_qa['explanation']}"
    
    # KB Ã¶zeti ekle (varsa)
    if kb_results:
        kb_summary = kb_results[0]["content"]["topic_summary"]
        answer += f"\n\nğŸ“š Ek Bilgi: {kb_summary[:200]}..."
    
    return answer  # HÄ±zlÄ± yanÄ±t (< 100ms)
```

#### AdÄ±m 4: Normal Yol (Direct Answer Yoksa)
```python
# Chunks + KB + QA birleÅŸtirilir
merged_results = retrieval_result["results"]["merged"]

# Reranking (isteÄŸe baÄŸlÄ±)
if request.use_crag:
    rerank_result = await rerank_documents(request.query, chunk_results)
    chunk_results = rerank_result["reranked_docs"][:request.top_k]

# Context oluÅŸturma
context = retriever.build_context_from_merged_results(
    merged_results=merged_results,
    max_chars=8000
)

# LLM ile cevap Ã¼retimi
llm_response = await generate_answer(
    query=request.query,
    context=context,
    model=effective_model
)
```

---

## 3. Topic Classification (Konu SÄ±nÄ±flandÄ±rmasÄ±)

### 3.1. Ä°ki AÅŸamalÄ± SÄ±nÄ±flandÄ±rma Stratejisi

Sistem, sorguyu konulara sÄ±nÄ±flandÄ±rmak iÃ§in **iki aÅŸamalÄ± bir strateji** kullanÄ±r:

#### AÅŸama 1: Anahtar Kelime TabanlÄ± SÄ±nÄ±flandÄ±rma (HÄ±zlÄ± ve GÃ¼venilir)

**AmaÃ§:** HÄ±zlÄ± ve gÃ¼venilir sÄ±nÄ±flandÄ±rma iÃ§in anahtar kelime eÅŸleÅŸtirmesi

**Ä°ÅŸlem AdÄ±mlarÄ±:**

1. **Sorgu Ä°ÅŸleme:**
   - Sorgu kÃ¼Ã§Ã¼k harfe Ã§evrilir
   - TÃ¼rkÃ§e stopword'ler filtrelenir
   - AnlamlÄ± kelimeler Ã§Ä±karÄ±lÄ±r (uzunluk > 2)

2. **TÃ¼rkÃ§e Stopword Listesi:**
   ```python
   stopwords = {
       'nedir', 'neden', 'nasÄ±l', 'ne', 'hangi', 'kim', 'nerede', 'ne zaman',
       'ile', 've', 'veya', 'iÃ§in', 'gibi', 'kadar', 'daha', 'Ã§ok', 'az',
       'bir', 'bu', 'ÅŸu', 'o', 'da', 'de', 'ki', 'mi', 'mÄ±', 'mu', 'mÃ¼'
   }
   ```

3. **EÅŸleÅŸtirme Kriterleri:**
   - **Anahtar Kelime EÅŸleÅŸmesi**: Topic'in keywords listesinde sorgu kelimeleri var mÄ±?
     - Tam eÅŸleÅŸme: +1.0 puan
     - KÄ±smi eÅŸleÅŸme: +0.5 puan
   - **BaÅŸlÄ±k EÅŸleÅŸmesi**: Topic baÅŸlÄ±ÄŸÄ±nda sorgu kelimeleri var mÄ±?
     - Her eÅŸleÅŸme: +1.5 puan (yÃ¼ksek aÄŸÄ±rlÄ±k)
   - **AÃ§Ä±klama EÅŸleÅŸmesi**: Topic aÃ§Ä±klamasÄ±nda sorgu kelimeleri var mÄ±?
     - Her eÅŸleÅŸme: +0.3 puan (dÃ¼ÅŸÃ¼k aÄŸÄ±rlÄ±k)

4. **GÃ¼ven Skoru Hesaplama:**
   ```python
   total_score = keyword_matches + (title_matches * 1.5) + description_matches
   max_possible = max(len(keywords), len(query_words), 1)
   confidence = min(total_score / max_possible, 1.0)
   
   # BaÅŸlÄ±k eÅŸleÅŸmesi varsa gÃ¼ven skoru artÄ±rÄ±lÄ±r
   if title_matches > 0:
       confidence = min(1.0, confidence * 1.2)
   ```

5. **SonuÃ§:**
   - En yÃ¼ksek gÃ¼ven skorlu 3 konu seÃ§ilir
   - GÃ¼ven skoru > 0.7 ise LLM'e gerek yok
   - GÃ¼ven skoru < 0.7 ise LLM sÄ±nÄ±flandÄ±rmasÄ±na geÃ§ilir

#### AÅŸama 2: LLM TabanlÄ± SÄ±nÄ±flandÄ±rma (Yedek YÃ¶ntem)

**KullanÄ±m SenaryolarÄ±:**
- Anahtar kelime gÃ¼ven skoru < 0.7
- KarmaÅŸÄ±k sorgular
- Ã‡oklu konu iÃ§eren sorgular

**LLM Prompt YapÄ±sÄ±:**
```
AÅŸaÄŸÄ±daki Ã¶ÄŸrenci sorusunu, verilen konu listesine gÃ¶re sÄ±nÄ±flandÄ±r.

Ã–ÄRENCÄ° SORUSU:
{query}

KONU LÄ°STESÄ°:
{topics_text}

Ã‡IKTI FORMATI (JSON):
{
  "matched_topics": [
    {
      "topic_id": 5,
      "topic_title": "HÃ¼cre ZarÄ±",
      "confidence": 0.92,
      "reasoning": "Soru hÃ¼cre zarÄ±nÄ±n yapÄ±sÄ± hakkÄ±nda"
    }
  ],
  "overall_confidence": 0.92
}
```

**Yedek MekanizmasÄ±:**
- LLM timeout (10 saniye) â†’ Anahtar kelime yÃ¶ntemine dÃ¶n
- LLM hata â†’ Anahtar kelime yÃ¶ntemine dÃ¶n
- LLM JSON parse hatasÄ± â†’ Anahtar kelime yÃ¶ntemine dÃ¶n

### 3.2. Ã–nbellekleme Stratejisi

**Ã–nbellek YapÄ±sÄ±:**
- **Anahtar:** Sorgu hash'i (MD5): `hashlib.md5(f"{session_id}:{query}")`
- **DeÄŸer:** SÄ±nÄ±flandÄ±rma sonucu + gÃ¼ven skoru
- **SÃ¼re:** 7 gÃ¼n
- **Tablo:** `topic_classification_cache`

**Ã–nbellek AvantajlarÄ±:**
- AynÄ± sorgular iÃ§in anÄ±nda yanÄ±t
- LLM Ã§aÄŸrÄ± sayÄ±sÄ±nda azalma
- Maliyet optimizasyonu

**Ã–nbellek KontrolÃ¼:**
```python
# Ã–nce Ã¶nbellek kontrol edilir
cache_result = db.execute("""
    SELECT classification_result, confidence
    FROM topic_classification_cache
    WHERE query_hash = ? AND session_id = ? 
      AND expires_at > CURRENT_TIMESTAMP
""", (query_hash, session_id))

if cache_result:
    return json.loads(cache_result["classification_result"])
```

---

## 4. Chunk-Based Retrieval (VektÃ¶r TabanlÄ± Arama)

### 4.1. Temel Ä°ÅŸlem AkÄ±ÅŸÄ±

**AÅŸamalar:**

1. **Sorgu Embedding OluÅŸturma:**
   - Model Inference Service'e gÃ¶nderilir
   - Embedding model: `text-embedding-v4` (varsayÄ±lan)
   - VektÃ¶r boyutu: Model'e gÃ¶re deÄŸiÅŸir

2. **VektÃ¶r Arama:**
   - ChromaDB'de cosine similarity ile arama
   - Top-K dokÃ¼man getirilir (varsayÄ±lan: 10)
   - Minimum skor: 0.3

3. **Anahtar Kelime Filtreleme ve BaÅŸlÄ±k ArtÄ±rÄ±mÄ±:**
   - Her chunk iÃ§in:
     - BaÅŸlÄ±kta anahtar kelime var mÄ±? â†’ BaÅŸlÄ±k artÄ±rÄ±mÄ± (+0.3)
     - Ä°Ã§erikte anahtar kelime var mÄ±? â†’ Ä°Ã§erik artÄ±rÄ±mÄ± (+0.2)

4. **Negatif Anahtar Kelime Filtreleme:**
   - ZÄ±t anlamlÄ± kelimeler tespit edilir
   - ZÄ±t anlamlÄ± kelime varsa: -0.2 ceza

5. **Final Skor Hesaplama:**
   ```python
   final_score = base_score + title_boost + content_boost + negative_penalty
   final_score = max(0.0, min(1.0, final_score))
   ```

### 4.2. TÃ¼rkÃ§e OptimizasyonlarÄ±

#### Anahtar Kelime Filtreleme

**AmaÃ§:** Sorgu anahtar kelimelerine gÃ¶re chunk'larÄ± filtreleme ve sÄ±ralama

**Ä°ÅŸlem:**
1. Sorgudan stopword'ler Ã§Ä±karÄ±lÄ±r
2. Anahtar kelimeler Ã§Ä±karÄ±lÄ±r (uzunluk > 2)
3. Her chunk iÃ§in:
   - BaÅŸlÄ±kta anahtar kelime var mÄ±? â†’ BaÅŸlÄ±k artÄ±rÄ±mÄ± (+0.3)
   - Ä°Ã§erikte anahtar kelime var mÄ±? â†’ Ä°Ã§erik artÄ±rÄ±mÄ± (+0.2)

**BaÅŸlÄ±k ArtÄ±rÄ±mÄ± Ã–rneÄŸi:**
```python
if query_words and chunk_title:
    title_matches = sum(1 for kw in query_words if kw in chunk_title)
    if title_matches > 0:
        title_boost = min(0.3, title_matches * 0.1)
```

#### Negatif Anahtar Kelime Filtreleme

**AmaÃ§:** ZÄ±t anlamlÄ± kelimeleri tespit ederek yanlÄ±ÅŸ chunk'larÄ± filtreleme

**ZÄ±t AnlamlÄ± Kelime Ã‡iftleri:**
```python
opposite_patterns = {
    'eÅŸeyli': 'eÅŸeysiz',
    'eÅŸeysiz': 'eÅŸeyli',
    'olumlu': 'olumsuz',
    'olumsuz': 'olumlu',
    'artÄ±': 'eksi',
    'eksi': 'artÄ±'
}
```

**Ceza Sistemi:**
- ZÄ±t anlamlÄ± kelime tespit edilirse: -0.2 ceza
- Final skor: `base_score + title_boost + content_boost + negative_penalty`

### 4.3. Embedding Model YÃ¶netimi

**VarsayÄ±lan Model:** `text-embedding-v4`

**Model SeÃ§imi:**
- Session RAG ayarlarÄ±ndan alÄ±nÄ±r
- Ä°stekten override edilebilir
- Yedek: VarsayÄ±lan model

**Ã–nemli Not:** Embedding model, vektÃ¶r deposu koleksiyonu ile uyumlu olmalÄ±dÄ±r. FarklÄ± modeller farklÄ± boyutlarda embedding Ã¼retir.

---

## 5. Knowledge Base (KB) Retrieval (Bilgi TabanÄ± EriÅŸimi)

### 5.1. KB YapÄ±sÄ±

Knowledge Base, yapÄ±landÄ±rÄ±lmÄ±ÅŸ bilgi iÃ§eren bir veritabanÄ± tablosudur:

**KB Tablosu YapÄ±sÄ±:**
```sql
topic_knowledge_base (
    knowledge_id INTEGER PRIMARY KEY,
    topic_id INTEGER,                    -- Konu ID'si
    topic_summary TEXT,                  -- Konu Ã¶zeti (ana iÃ§erik)
    key_concepts TEXT,                   -- JSON: Anahtar kavramlar listesi
    learning_objectives TEXT,            -- JSON: Ã–ÄŸrenme hedefleri listesi
    examples TEXT,                       -- JSON: Ã–rnekler listesi
    content_quality_score REAL,          -- Ä°Ã§erik kalite skoru (0.0-1.0)
    created_at TIMESTAMP,
    updated_at TIMESTAMP
)
```

### 5.2. KB EriÅŸim Ä°ÅŸlemi

**AÅŸamalar:**

1. **Konu EÅŸleÅŸtirme:**
   - Topic classification sonuÃ§larÄ±ndan `topic_id`'ler alÄ±nÄ±r
   - Her eÅŸleÅŸen konu iÃ§in KB entry'si sorgulanÄ±r

2. **EriÅŸim Kriterleri:**
   - Topic classification gÃ¼ven skoru > 0.7 (`kb_usage_threshold`)
   - `topic_id` ile eÅŸleÅŸen KB entry'si var mÄ±?
   - Entry aktif mi? (varsa `is_active` kontrolÃ¼)

3. **Veri Ã‡ekme:**
   ```sql
   SELECT 
       kb.knowledge_id,
       kb.topic_id,
       kb.topic_summary,
       kb.key_concepts,
       kb.learning_objectives,
       kb.examples,
       kb.content_quality_score,
       t.topic_title
   FROM topic_knowledge_base kb
   JOIN course_topics t ON kb.topic_id = t.topic_id
   WHERE kb.topic_id = ?
   ```

4. **JSON AlanlarÄ±nÄ± Parse Etme:**
   ```python
   kb_dict["key_concepts"] = json.loads(kb_dict["key_concepts"]) if kb_dict["key_concepts"] else []
   kb_dict["learning_objectives"] = json.loads(kb_dict["learning_objectives"]) if kb_dict["learning_objectives"] else []
   kb_dict["examples"] = json.loads(kb_dict["examples"]) if kb_dict["examples"] else []
   ```

5. **SonuÃ§ FormatÄ±:**
   ```python
   kb_result = {
       "type": "knowledge_base",
       "topic_id": topic["topic_id"],
       "topic_title": kb_dict["topic_title"],
       "content": {
           "topic_summary": kb_dict["topic_summary"],
           "key_concepts": kb_dict["key_concepts"],
           "learning_objectives": kb_dict["learning_objectives"],
           "examples": kb_dict["examples"]
       },
       "relevance_score": topic["confidence"],  # Topic classification gÃ¼ven skoru
       "quality_score": kb_dict["content_quality_score"]
   }
   ```

### 5.3. KB Ä°Ã§erik YapÄ±sÄ±

#### Topic Summary (Konu Ã–zeti)
- Konunun kapsamlÄ± Ã¶zeti
- Ana kavramlar ve iliÅŸkiler
- Ã–ÄŸrenme hedefleri
- **KullanÄ±m:** LLM context'ine eklenir

#### Key Concepts (Anahtar Kavramlar)
- JSON array formatÄ±nda
- Her kavram iÃ§in aÃ§Ä±klama
- **Ã–rnek:**
  ```json
  [
    "Fosfolipid: HÃ¼cre zarÄ±nÄ±n ana bileÅŸeni",
    "Protein: HÃ¼cre zarÄ±nda bulunan yapÄ±sal ve iÅŸlevsel molekÃ¼ller",
    "Kolesterol: HÃ¼cre zarÄ±nÄ±n akÄ±ÅŸkanlÄ±ÄŸÄ±nÄ± dÃ¼zenleyen molekÃ¼l"
  ]
  ```

#### Learning Objectives (Ã–ÄŸrenme Hedefleri)
- JSON array formatÄ±nda
- Bloom taksonomisi seviyeleri
- **Ã–rnek:**
  ```json
  [
    "HÃ¼cre zarÄ±nÄ±n yapÄ±sÄ±nÄ± aÃ§Ä±klama (Anlama)",
    "HÃ¼cre zarÄ±nÄ±n fonksiyonlarÄ±nÄ± belirleme (Analiz)",
    "HÃ¼cre zarÄ± modellerini karÅŸÄ±laÅŸtÄ±rma (DeÄŸerlendirme)"
  ]
  ```

#### Examples (Ã–rnekler)
- JSON array formatÄ±nda
- Pratik Ã¶rnekler
- GerÃ§ek hayat senaryolarÄ±
- **Ã–rnek:**
  ```json
  [
    "HÃ¼cre zarÄ±, hÃ¼creyi dÄ±ÅŸ ortamdan ayÄ±ran yapÄ±dÄ±r. Ã–rneÄŸin, bitki hÃ¼crelerinde selÃ¼loz duvarÄ± bulunurken, hayvan hÃ¼crelerinde sadece hÃ¼cre zarÄ± vardÄ±r.",
    "HÃ¼cre zarÄ±nÄ±n seÃ§ici geÃ§irgenliÄŸi sayesinde, hÃ¼cre iÃ§ine sadece gerekli maddeler alÄ±nÄ±r."
  ]
  ```

### 5.4. KB KullanÄ±m SenaryolarÄ±

**KullanÄ±m:**
- Kavramsal bilgi saÄŸlama
- Ã–ÄŸrenme hedeflerini belirleme
- Ã–rneklerle zenginleÅŸtirme
- YapÄ±landÄ±rÄ±lmÄ±ÅŸ bilgi eriÅŸimi

**Avantajlar:**
- HÄ±zlÄ± eriÅŸim (veritabanÄ± sorgusu)
- YapÄ±landÄ±rÄ±lmÄ±ÅŸ bilgi
- Kalite skoru ile filtreleme
- Topic classification gÃ¼ven skoru ile relevance scoring

**LLM Context'ine Entegrasyon:**
```python
# KB Ã¶zeti context'e eklenir
kb_summary = kb_result["content"]["topic_summary"]
context += f"\n\n[BÄ°LGÄ° TABANI]\n{kb_summary}\n"

# Anahtar kavramlar eklenir (isteÄŸe baÄŸlÄ±)
if kb_result["content"]["key_concepts"]:
    concepts = "\n".join(kb_result["content"]["key_concepts"])
    context += f"\nAnahtar Kavramlar:\n{concepts}\n"
```

---

## 6. QA Pair Matching (Soru-Cevap EÅŸleÅŸtirme)

### 6.1. QA Pair YapÄ±sÄ±

**QA Tablosu YapÄ±sÄ±:**
```sql
topic_qa_pairs (
    qa_id INTEGER PRIMARY KEY,
    topic_id INTEGER,                    -- Konu ID'si
    question TEXT,                       -- Soru metni
    answer TEXT,                         -- Cevap metni
    explanation TEXT,                    -- AÃ§Ä±klama (opsiyonel)
    difficulty_level TEXT,               -- Zorluk seviyesi
    question_type TEXT,                  -- Soru tipi
    bloom_taxonomy_level TEXT,           -- Bloom seviyesi
    times_asked INTEGER,                 -- KaÃ§ kez soruldu
    times_matched INTEGER,               -- KaÃ§ kez eÅŸleÅŸti
    average_student_rating REAL,         -- Ortalama Ã¶ÄŸrenci puanÄ±
    question_embedding TEXT,             -- Soru embedding'i (JSON array)
    embedding_model TEXT,                -- KullanÄ±lan embedding modeli
    embedding_dim INTEGER,               -- Embedding boyutu
    is_active BOOLEAN,                   -- Aktif mi?
    created_at TIMESTAMP,
    updated_at TIMESTAMP
)
```

### 6.2. QA EÅŸleÅŸtirme Ä°ÅŸlemi

#### AÅŸama 1: Ã–nbellek KontrolÃ¼

**Ã–nbellek YapÄ±sÄ±:**
- **Anahtar:** Sorgu hash'i (MD5): `hashlib.md5(query.encode())`
- **DeÄŸer:** EÅŸleÅŸen QA ID'leri + benzerlik skorlarÄ±
- **SÃ¼re:** 30 gÃ¼n
- **Tablo:** `qa_similarity_cache`

**Ã–nbellek KontrolÃ¼:**
```python
cache_hit = db.execute("""
    SELECT matched_qa_ids, embedding_model 
    FROM qa_similarity_cache
    WHERE question_text_hash = ? 
      AND expires_at > CURRENT_TIMESTAMP
""", (query_hash,))

if cache_hit and cache_hit["embedding_model"] == embedding_model:
    return json.loads(cache_hit["matched_qa_ids"])  # Ã–nbellekten dÃ¶n
```

#### AÅŸama 2: QA Pair Ã‡ekme

**Kriterler:**
- `topic_id`'ler: EÅŸleÅŸen konulardan alÄ±nan topic_id'ler
- `is_active = TRUE`
- `question_embedding IS NOT NULL` (optimizasyon iÃ§in)
- `embedding_model = requested_model` (model uyumu)

**SÄ±ralama:**
- `times_asked DESC` (en Ã§ok sorulanlar Ã¶nce)
- `average_student_rating DESC` (en yÃ¼ksek puanlÄ±lar Ã¶nce)

**Limit:** 50 QA pair (performans iÃ§in)

**Sorgu:**
```sql
SELECT qa_id, topic_id, question, answer, explanation,
       difficulty_level, question_type, bloom_taxonomy_level,
       times_asked, average_student_rating,
       question_embedding, embedding_model, embedding_dim
FROM topic_qa_pairs
WHERE topic_id IN (?, ?, ?) 
  AND is_active = TRUE
  AND question_embedding IS NOT NULL
  AND embedding_model = ?
ORDER BY times_asked DESC, average_student_rating DESC
LIMIT 50
```

#### AÅŸama 3: Benzerlik Hesaplama

**ÃœÃ§ FarklÄ± YÃ¶ntem (Performans SÄ±rasÄ±na GÃ¶re):**

##### YÃ¶ntem 1: SaklÄ± Embedding'ler (En HÄ±zlÄ±) âš¡

**Avantajlar:**
- QA soru embedding'leri Ã¶nceden hesaplanmÄ±ÅŸ ve saklanmÄ±ÅŸ
- Sadece sorgu embedding'i hesaplanÄ±r (1 API Ã§aÄŸrÄ±sÄ±)
- Cosine benzerliÄŸi numpy ile hÄ±zlÄ± hesaplanÄ±r

**Ä°ÅŸlem:**
1. QA pair'lerden saklÄ± embedding'leri al
2. Sorgu embedding'ini hesapla (1 API Ã§aÄŸrÄ±sÄ±)
3. Toplu cosine benzerliÄŸi (numpy vektÃ¶rleÅŸtirilmiÅŸ)
4. EÅŸik: > 0.75

**Performans:** ~10-50ms (50 QA pair iÃ§in)

**Kod:**
```python
# SaklÄ± embedding'leri parse et
stored_embeddings = []
for qa in qa_pairs:
    if qa.get("question_embedding") and qa.get("embedding_model") == embedding_model:
        stored_embedding = json.loads(qa["question_embedding"])
        stored_embeddings.append(np.array(stored_embedding, dtype=np.float32))

# Sorgu embedding'ini hesapla (1 API Ã§aÄŸrÄ±sÄ±)
query_embedding = await get_embedding(query, embedding_model)

# Toplu cosine benzerliÄŸi
similarities = np.dot(stored_embeddings, query_embedding)

# EÅŸik kontrolÃ¼
for i, similarity in enumerate(similarities):
    if similarity > 0.75:
        qa_with_similarity.append({
            "qa_id": qa_pairs[i]["qa_id"],
            "similarity_score": similarity,
            ...
        })
```

##### YÃ¶ntem 2: Toplu Embedding (Orta HÄ±zlÄ±) ğŸš€

**KullanÄ±m:** SaklÄ± embedding'ler yoksa

**Avantajlar:**
- TÃ¼m QA sorularÄ± tek toplu iÅŸlemde embed edilir
- 1 API Ã§aÄŸrÄ±sÄ± (sorgu + tÃ¼m QA sorularÄ±)
- Cosine benzerliÄŸi numpy ile hesaplanÄ±r

**Ä°ÅŸlem:**
1. TÃ¼m metinleri hazÄ±rla: `[query] + [qa.question for qa in qa_pairs]`
2. Toplu embedding API Ã§aÄŸrÄ±sÄ± (1 Ã§aÄŸrÄ±)
3. Toplu cosine benzerliÄŸi
4. EÅŸik: > 0.75

**Performans:** ~200-500ms (50 QA pair iÃ§in)

##### YÃ¶ntem 3: Bireysel Hesaplama (Yedek) ğŸ”„

**KullanÄ±m:** Toplu embedding baÅŸarÄ±sÄ±z olursa

**Ä°ÅŸlem:**
- Her QA pair iÃ§in ayrÄ± ayrÄ± benzerlik hesapla
- Her biri iÃ§in embedding API Ã§aÄŸrÄ±sÄ±

**Performans:** ~2-5 saniye (50 QA pair iÃ§in)

### 6.3. Benzerlik EÅŸikleri ve Direkt Cevap

**EÅŸik DeÄŸerleri:**
- **0.75**: Minimum relevance (QA pair listesine eklenir)
- **0.85**: YÃ¼ksek relevance (birleÅŸtirilmiÅŸ sonuÃ§lara eklenir)
- **0.90**: Ã‡ok yÃ¼ksek relevance â†’ **Direkt Cevap** (hÄ±zlÄ± yol)

**Direkt Cevap MekanizmasÄ±:**
```python
if top_qa["similarity_score"] > 0.90:
    # HIZLI YOL: DoÄŸrudan QA pair'den cevap
    # LLM generation'a gerek yok
    answer = direct_qa["answer"]
    if direct_qa.get("explanation"):
        answer += f"\n\nğŸ’¡ {direct_qa['explanation']}"
    
    # KB Ã¶zeti ekle (varsa)
    if kb_results:
        kb_summary = kb_results[0]["content"]["topic_summary"]
        answer += f"\n\nğŸ“š Ek Bilgi: {kb_summary[:200]}..."
    
    return answer  # HÄ±zlÄ± yanÄ±t (< 100ms)
```

**Direkt Cevap AvantajlarÄ±:**
- Ã‡ok hÄ±zlÄ± yanÄ±t (< 100ms)
- LLM maliyeti yok
- YÃ¼ksek doÄŸruluk (Ã¶nceden hazÄ±rlanmÄ±ÅŸ cevap)

### 6.4. TÃ¼rkÃ§e QA EÅŸleÅŸtirme OptimizasyonlarÄ±

#### Embedding Model Uyumu

**Ã–nemli:** QA pair'lerin embedding'leri, sorgu embedding'i ile aynÄ± model ile hesaplanmÄ±ÅŸ olmalÄ±dÄ±r.

**Model KontrolÃ¼:**
- QA pair'de `embedding_model` kolonu kontrol edilir
- EÅŸleÅŸmezse, saklÄ± embedding kullanÄ±lmaz
- Yedek: Toplu embedding

#### TÃ¼rkÃ§e Morfoloji DesteÄŸi

**Sorun:** TÃ¼rkÃ§e'nin eklemeli yapÄ±sÄ±, embedding'lerde farklÄ±lÄ±klara yol aÃ§abilir.

**Ã‡Ã¶zÃ¼m:**
- TÃ¼rkÃ§e iÃ§in optimize edilmiÅŸ embedding modelleri kullanÄ±mÄ±
- `text-embedding-v4` modeli TÃ¼rkÃ§e iÃ§in optimize edilmiÅŸtir
- Benzerlik eÅŸiÄŸi TÃ¼rkÃ§e iÃ§in ayarlanabilir (0.75)

### 6.5. QA KullanÄ±m Takibi

**Takip Verileri:**
- `qa_id`
- `user_id`
- `session_id`
- `original_question`
- `similarity_score`
- `response_time_ms`
- `response_source`: "direct_qa"

**KullanÄ±m:**
- Analitik iÃ§in
- QA pair kalitesini deÄŸerlendirme
- En Ã§ok kullanÄ±lan QA pair'leri belirleme

**Takip Sorgusu:**
```sql
INSERT INTO student_qa_interactions (
    qa_id, user_id, session_id, original_question,
    similarity_score, response_time_ms, response_source
) VALUES (?, ?, ?, ?, ?, ?, ?)

UPDATE topic_qa_pairs
SET times_matched = times_matched + 1
WHERE qa_id = ?
```

---

## 7. Results Merging (SonuÃ§ BirleÅŸtirme)

### 7.1. BirleÅŸtirme Stratejileri

#### Strateji 1: AÄŸÄ±rlÄ±klÄ± BirleÅŸtirme (VarsayÄ±lan)

**AÄŸÄ±rlÄ±klar:**
- **Chunks**: 40% (geleneksel RAG temel Ã§izgisi)
- **Knowledge Base**: 30% (yapÄ±landÄ±rÄ±lmÄ±ÅŸ bilgi)
- **QA Pairs**: 30% (doÄŸrudan eÅŸleÅŸme)

**Final Skor Hesaplama:**
```python
chunk_final_score = crag_score * 0.4
kb_final_score = relevance_score * 0.3
qa_final_score = similarity_score * 0.3
```

**KullanÄ±m:**
- En iyi 8 chunk
- TÃ¼m KB entry'leri
- En iyi 3 QA eÅŸleÅŸmesi (benzerlik > 0.85)

**BirleÅŸtirme Kodu:**
```python
# CHUNKS: 40% aÄŸÄ±rlÄ±k
for i, chunk in enumerate(chunk_results[:8]):
    merged.append({
        "content": chunk.get("content", ""),
        "source": "chunk",
        "final_score": chunk.get("crag_score", chunk.get("score", 0.5)) * 0.4,
        ...
    })

# KNOWLEDGE BASE: 30% aÄŸÄ±rlÄ±k
for kb in kb_results:
    merged.append({
        "content": kb["content"]["topic_summary"],
        "source": "knowledge_base",
        "final_score": kb["relevance_score"] * 0.3,
        ...
    })

# QA PAIRS: 30% aÄŸÄ±rlÄ±k
for qa in qa_matches[:3]:
    if qa["similarity_score"] > 0.85:
        merged.append({
            "content": f"SORU: {qa['question']}\n\nCEVAP: {qa['answer']}",
            "source": "qa_pair",
            "final_score": qa["similarity_score"] * 0.3,
            ...
        })
```

#### Strateji 2: KarÅŸÄ±lÄ±klÄ± SÄ±ralama BirleÅŸtirmesi (RRF)

**FormÃ¼l:**
```
RRF_score = 1 / (k + rank)
k = 60 (varsayÄ±lan)
```

**Avantajlar:**
- SÄ±ralama tabanlÄ± birleÅŸtirme
- Kaynak tipinden baÄŸÄ±msÄ±z
- Daha dengeli daÄŸÄ±lÄ±m

### 7.2. Context OluÅŸturma

**AmaÃ§:** BirleÅŸtirilmiÅŸ sonuÃ§lardan LLM iÃ§in context string oluÅŸturma

**Format:**
```
[DERS MATERYALÄ° #1]
{chunk_content}

---

[BÄ°LGÄ° TABANI #2]
{kb_summary}

---

[SORU-CEVAP #3]
SORU: {qa_question}
CEVAP: {qa_answer}
```

**Uzunluk Limiti:**
- VarsayÄ±lan: 8000 karakter
- Ayarlanabilir: `max_chars` parametresi

**SÄ±ralama:**
- Final skoruna gÃ¶re sÄ±ralÄ±
- En yÃ¼ksek skorlu iÃ§erikler Ã¶nce

**Context OluÅŸturma Kodu:**
```python
context_parts = []
current_length = 0

for i, result in enumerate(merged_results):
    content = result["content"]
    source = result["source"]
    
    # Kaynak etiketi ile formatla
    source_label = {
        "chunk": "DERS MATERYALÄ°",
        "knowledge_base": "BÄ°LGÄ° TABANI",
        "qa_pair": "SORU-CEVAP"
    }.get(source, "KAYNAK")
    
    formatted = f"[{source_label} #{i+1}]\n{content}\n"
    
    # Uzunluk kontrolÃ¼
    if current_length + len(formatted) > max_chars:
        break
    
    context_parts.append(formatted)
    current_length += len(formatted)

context = "\n---\n\n".join(context_parts)
```

---

## 8. TÃ¼rkÃ§e Dil DesteÄŸi ve Optimizasyonlar

### 8.1. TÃ¼rkÃ§e Morfoloji DesteÄŸi

**Sorunlar:**
- TÃ¼rkÃ§e eklemeli bir dildir
- Kelimeler Ã§ok uzun olabilir
- Ã‡ekim ekleri embedding'leri etkileyebilir

**Ã‡Ã¶zÃ¼mler:**
- TÃ¼rkÃ§e iÃ§in optimize edilmiÅŸ embedding modelleri
- Stopword filtreleme (TÃ¼rkÃ§e stopword listesi)
- Anahtar kelime Ã§Ä±karma (uzunluk > 2)

### 8.2. TÃ¼rkÃ§e Stopword Filtreleme

**Stopword Kategorileri:**
- Soru kelimeleri: nedir, neden, nasÄ±l, ne, hangi, kim, nerede, ne zaman
- BaÄŸlaÃ§lar: ile, ve, veya, iÃ§in, gibi, kadar
- SÄ±fatlar: daha, Ã§ok, az
- Zamirler: bir, bu, ÅŸu, o
- Ekler: da, de, ki, mi, mÄ±, mu, mÃ¼

**Filtreleme:**
- Stopword'ler sorgu kelimelerinden Ã§Ä±karÄ±lÄ±r
- Sadece anlamlÄ± kelimeler kullanÄ±lÄ±r
- Uzunluk kontrolÃ¼: len(word) > 2

### 8.3. TÃ¼rkÃ§e Anahtar Kelime EÅŸleÅŸtirmesi

**Tam EÅŸleÅŸme:**
- Tam kelime eÅŸleÅŸmesi
- BÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf duyarsÄ±z

**KÄ±smi EÅŸleÅŸme:**
- Kelime iÃ§inde geÃ§me
- TÃ¼rkÃ§e stemming iÃ§in

**BaÅŸlÄ±k ArtÄ±rÄ±mÄ±:**
- BaÅŸlÄ±kta geÃ§en kelimeler yÃ¼ksek aÄŸÄ±rlÄ±k alÄ±r
- +0.3 artÄ±rÄ±m (maksimum)

### 8.4. TÃ¼rkÃ§e Embedding Modelleri

**Ã–nerilen Modeller:**
- `text-embedding-v4`: TÃ¼rkÃ§e iÃ§in optimize edilmiÅŸ
- Ã‡ok dilli modeller: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`

**Model SeÃ§imi:**
- Session RAG ayarlarÄ±ndan alÄ±nÄ±r
- Ä°stekten override edilebilir
- Yedek: VarsayÄ±lan model

---

## 9. Performans OptimizasyonlarÄ±

### 9.1. Ã–nbellekleme Stratejileri

#### Topic Classification Ã–nbelleÄŸi
- **SÃ¼re:** 7 gÃ¼n
- **Anahtar:** Sorgu hash'i (MD5)
- **DeÄŸer:** SÄ±nÄ±flandÄ±rma sonucu + gÃ¼ven skoru

#### QA Benzerlik Ã–nbelleÄŸi
- **SÃ¼re:** 30 gÃ¼n
- **Anahtar:** Sorgu hash'i (MD5)
- **DeÄŸer:** EÅŸleÅŸen QA ID'leri + benzerlik skorlarÄ±
- **Model KontrolÃ¼:** Embedding model uyumu kontrol edilir

### 9.2. Toplu Ä°ÅŸleme

#### Embedding Toplu Ä°ÅŸlemi
- TÃ¼m metinler tek toplu iÅŸlemde embed edilir
- 1 API Ã§aÄŸrÄ±sÄ± (50+ metin iÃ§in)
- Maliyet ve sÃ¼re tasarrufu

#### Benzerlik Hesaplama
- Numpy vektÃ¶rleÅŸtirilmiÅŸ iÅŸlemler
- Toplu cosine benzerliÄŸi
- CPU'da hÄ±zlÄ± hesaplama

### 9.3. Zaman AÅŸÄ±mÄ± YÃ¶netimi

**Zaman AÅŸÄ±mÄ± DeÄŸerleri:**
- Topic Classification: 10 saniye
- Chunk Retrieval: 60 saniye
- QA Embedding: 10-30 saniye (toplu iÅŸlem boyutuna gÃ¶re)
- LLM Generation: 60 saniye

**Yedek MekanizmasÄ±:**
- Zaman aÅŸÄ±mÄ± durumunda yedek yÃ¶ntemler kullanÄ±lÄ±r
- Zarif dÃ¼ÅŸÃ¼ÅŸ
- KullanÄ±cÄ±ya hata mesajÄ± gÃ¶sterilmez (sessiz yedek)

### 9.4. Zarif DÃ¼ÅŸÃ¼ÅŸ

**Yedek HiyerarÅŸisi:**
1. **SaklÄ± Embedding'ler** â†’ BaÅŸarÄ±sÄ±z olursa
2. **Toplu Embedding** â†’ BaÅŸarÄ±sÄ±z olursa
3. **Bireysel Hesaplama** â†’ BaÅŸarÄ±sÄ±z olursa
4. **Kelime Ã–rtÃ¼ÅŸmesi BenzerliÄŸi** â†’ Son Ã§are

**KullanÄ±cÄ± Deneyimi:**
- Yedek'ler kullanÄ±cÄ±ya gÃ¶rÃ¼nmez
- Sistem her zaman bir yanÄ±t Ã¼retir
- Performans dÃ¼ÅŸse bile Ã§alÄ±ÅŸÄ±r

---

## 10. Sistem AkÄ±ÅŸÄ±: DetaylÄ± Ã–rnek

### 10.1. Ã–rnek Sorgu: "HÃ¼cre zarÄ±nÄ±n yapÄ±sÄ± nedir?"

#### AdÄ±m 1: Topic Classification
```
Sorgu: "HÃ¼cre zarÄ±nÄ±n yapÄ±sÄ± nedir?"
â†“
Anahtar Kelime Ã‡Ä±karma: ["hÃ¼cre", "zarÄ±", "yapÄ±sÄ±"]
â†“
Topic EÅŸleÅŸtirme:
- Topic: "HÃ¼cre ZarÄ±" (topic_id: 5)
- GÃ¼ven Skoru: 0.92 (anahtar kelime + baÅŸlÄ±k eÅŸleÅŸmesi)
â†“
EÅŸleÅŸen Konular: [{"topic_id": 5, "topic_title": "HÃ¼cre ZarÄ±", "confidence": 0.92}]
```

#### AdÄ±m 2: Paralel Bilgi EriÅŸimi

**Chunk Retrieval:**
```
VektÃ¶r Arama â†’ En iyi 10 chunk
Anahtar Kelime Filtreleme:
- BaÅŸlÄ±k artÄ±rÄ±mÄ±: +0.2 ("hÃ¼cre zarÄ±" baÅŸlÄ±kta geÃ§iyor)
- Ä°Ã§erik artÄ±rÄ±mÄ±: +0.15
- Final skor: 0.87
â†“
Chunks: 10 adet (sÄ±ralÄ±)
```

**KB Retrieval:**
```
Topic ID: 5 â†’ KB Entry bulundu
Topic Summary: "HÃ¼cre zarÄ±, hÃ¼creyi Ã§evreleyen..."
Key Concepts: ["Fosfolipid", "Protein", "Kolesterol"]
Learning Objectives: ["YapÄ±yÄ± aÃ§Ä±klama", "FonksiyonlarÄ± belirleme"]
â†“
KB Entry: 1 adet
```

**QA Pair Matching:**
```
Topic ID: 5 â†’ 50 QA pair Ã§ekildi
SaklÄ± Embedding'ler: 45 adet mevcut
Sorgu Embedding: 1 API Ã§aÄŸrÄ±sÄ±
Toplu Benzerlik: Numpy vektÃ¶rleÅŸtirilmiÅŸ
â†“
En iyi 3 QA eÅŸleÅŸmesi:
- QA #12: benzerlik=0.91 (Direkt Cevap!)
- QA #8: benzerlik=0.87
- QA #15: benzerlik=0.82
```

#### AdÄ±m 3: Direkt Cevap KontrolÃ¼
```
En iyi QA benzerliÄŸi: 0.91 > 0.90
â†“
HIZLI YOL: Direkt Cevap
- LLM generation'a gerek yok
- QA #12'den direkt cevap
- YanÄ±t sÃ¼resi: < 100ms
```

#### AdÄ±m 4: SonuÃ§ BirleÅŸtirme (EÄŸer Direkt Cevap Yoksa)
```
AÄŸÄ±rlÄ±klÄ± BirleÅŸtirme:
- Chunks (40%): 8 adet
- KB (30%): 1 adet
- QA (30%): 3 adet
â†“
BirleÅŸtirilmiÅŸ SonuÃ§lar: 12 adet (sÄ±ralÄ±)
```

#### AdÄ±m 5: Context OluÅŸturma
```
[DERS MATERYALÄ° #1]
HÃ¼cre zarÄ±, hÃ¼creyi Ã§evreleyen...

---

[BÄ°LGÄ° TABANI #2]
HÃ¼cre zarÄ±, hÃ¼creyi Ã§evreleyen yapÄ±dÄ±r...

---

[SORU-CEVAP #3]
SORU: HÃ¼cre zarÄ±nÄ±n yapÄ±sÄ± nedir?
CEVAP: HÃ¼cre zarÄ± fosfolipid Ã§ift katmanÄ±ndan...
```

#### AdÄ±m 6: LLM Generation (EÄŸer Direkt Cevap Yoksa)
```
Context + Sorgu â†’ LLM
â†“
KiÅŸiselleÅŸtirilmiÅŸ YanÄ±t
```

---

## 11. Ã–nemli TasarÄ±m KararlarÄ±

### 11.1. Neden Hibrit YaklaÅŸÄ±m?

**Sorun:** Tek kaynaklÄ± yaklaÅŸÄ±mlarÄ±n sÄ±nÄ±rlamalarÄ±
- Chunks: YapÄ±landÄ±rÄ±lmamÄ±ÅŸ, parÃ§alÄ± bilgi
- KB: Sadece kavramsal bilgi, detay eksik
- QA: Sadece Ã¶nceden hazÄ±rlanmÄ±ÅŸ sorular

**Ã‡Ã¶zÃ¼m:** ÃœÃ§ kaynaÄŸÄ± birleÅŸtirme
- Chunks: DetaylÄ±, parÃ§alÄ± bilgi
- KB: YapÄ±landÄ±rÄ±lmÄ±ÅŸ, kavramsal bilgi
- QA: HÄ±zlÄ±, doÄŸrudan cevaplar

**SonuÃ§:** Daha kapsamlÄ± ve doÄŸru bilgi eriÅŸimi

### 11.2. Neden Topic Classification?

**Sorun:** TÃ¼m veritabanÄ±nda arama yavaÅŸ ve verimsiz

**Ã‡Ã¶zÃ¼m:** Ã–nce konuya sÄ±nÄ±flandÄ±r, sonra o konu iÃ§inde ara
- HÄ±zlÄ±: Sadece ilgili konularda arama
- DoÄŸru: Ä°lgisiz konular filtrelenir
- Verimli: Daha az veri iÅŸlenir

### 11.3. Neden Ã–nbellekleme?

**Sorun:** AynÄ± sorgular tekrar tekrar iÅŸleniyor

**Ã‡Ã¶zÃ¼m:** SonuÃ§larÄ± Ã¶nbellekle
- HÄ±zlÄ±: Ã–nbellek isabetinde anÄ±nda yanÄ±t
- Maliyet: LLM/embedding Ã§aÄŸrÄ±larÄ± azalÄ±r
- Performans: Sistem yÃ¼kÃ¼ azalÄ±r

### 11.4. Neden SaklÄ± Embedding'ler?

**Sorun:** QA pair'ler iÃ§in her seferinde embedding hesaplama

**Ã‡Ã¶zÃ¼m:** Embedding'leri Ã¶nceden hesapla ve sakla
- HÄ±zlÄ±: Sadece sorgu embedding hesaplanÄ±r
- Verimli: Toplu benzerlik numpy ile
- Ã–lÃ§eklenebilir: Binlerce QA pair iÃ§in Ã§alÄ±ÅŸÄ±r

---

## 12. Sistem Limitleri ve Gelecek GeliÅŸtirmeler

### 12.1. Mevcut Limitler

- **Top-K Chunks:** 10 (varsayÄ±lan, ayarlanabilir)
- **QA Pair Limiti:** 50 (Ã§ekme), 5 (dÃ¶ndÃ¼rme)
- **Context UzunluÄŸu:** 8000 karakter (varsayÄ±lan)
- **Ã–nbellek SÃ¼resi:** 7-30 gÃ¼n

### 12.2. Gelecek GeliÅŸtirmeler

- **Graph RAG:** Kavramsal iliÅŸkileri graph olarak modelleme
- **Ã‡ok Modlu EriÅŸim:** GÃ¶rsel + metin birleÅŸtirme
- **GerÃ§ek ZamanlÄ± Ã–ÄŸrenme:** Online learning ile sÃ¼rekli gÃ¼ncelleme
- **GeliÅŸmiÅŸ Yeniden SÄ±ralama:** Cross-encoder modelleri
- **Sorgu GeniÅŸletme:** TÃ¼rkÃ§e iÃ§in Ã¶zel sorgu geniÅŸletme teknikleri

---

**HazÄ±rlanma Tarihi**: 2025-12-05
**Durum**: DetaylÄ± Sistem Mimarisi DokÃ¼mantasyonu
**Versiyon**: 2.0 (Tamamen TÃ¼rkÃ§e, GerÃ§ek KullanÄ±m DetaylarÄ±)
