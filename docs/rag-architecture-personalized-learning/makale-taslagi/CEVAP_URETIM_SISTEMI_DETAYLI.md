# Cevap Ãœretim Sistemi: Ã–ÄŸrenci SorularÄ±nÄ±n CevaplanmasÄ± ve LLM Entegrasyonu

## 1. Genel BakÄ±ÅŸ

Bu dokÃ¼mantasyon, Ã¶ÄŸrenci sorularÄ±nÄ±n nasÄ±l cevaplandÄ±ÄŸÄ±nÄ±, cevap Ã¼retim sÃ¼recini, kullanÄ±lan teknolojileri ve prompt engineering stratejilerini detaylÄ± olarak aÃ§Ä±klamaktadÄ±r.

### 1.1. Cevap Ãœretim Mimarisi

```
Ã–ÄŸrenci Sorgusu
    â†“
Hybrid Retrieval (Chunks + KB + QA)
    â†“
Context Building
    â†“
LLM Prompt Engineering
    â†“
LLM Generation (Groq/Alibaba/OpenRouter)
    â†“
Answer Post-Processing
    â†“
Personalization (Opsiyonel)
    â†“
Final Response
```

---

## 2. Cevap Ãœretim SÃ¼reci

### 2.1. AdÄ±m 1: Hybrid Retrieval

**AmaÃ§:** Ã–ÄŸrenci sorusu iÃ§in en uygun bilgileri toplama

**SÃ¼reÃ§:**
1. **Topic Classification**: Soruyu konuya eÅŸleÅŸtirme
2. **Chunk Retrieval**: Vector search ile ilgili metin parÃ§alarÄ±
3. **KB Retrieval**: Structured knowledge (topic summary, concepts)
4. **QA Matching**: Direkt cevap eÅŸleÅŸmesi kontrolÃ¼

**Ã‡Ä±ktÄ±:** `merged_results` - BirleÅŸtirilmiÅŸ ve sÄ±ralanmÄ±ÅŸ bilgi kaynaklarÄ±

### 2.2. AdÄ±m 2: Context Building

**AmaÃ§:** LLM iÃ§in optimize edilmiÅŸ context string oluÅŸturma

**Fonksiyon:** `build_context_from_merged_results()`

**SÃ¼reÃ§:**
```python
def build_context_from_merged_results(
    merged_results: List[Dict],
    max_chars: int = 8000,
    include_sources: bool = True
) -> str:
    """
    Build context string from merged results for LLM
    
    Format:
    [DERS MATERYALÄ° #1]
    {chunk_content}
    
    ---
    
    [BÄ°LGÄ° TABANI #2]
    {kb_summary}
    
    ---
    
    [SORU-CEVAP #3]
    {qa_answer}
    """
```

**Kaynak Etiketleme:**
- `chunk` â†’ `[DERS MATERYALÄ° #N]`
- `knowledge_base` â†’ `[BÄ°LGÄ° TABANI #N]`
- `qa_pair` â†’ `[SORU-CEVAP #N]`

**Uzunluk YÃ¶netimi:**
- VarsayÄ±lan maksimum: 8000 karakter
- Kaynaklar sÄ±rayla eklenir
- Limit aÅŸÄ±lÄ±rsa kesilir

**Ã–rnek Context:**
```
[DERS MATERYALÄ° #1]
HÃ¼cre zarÄ±, hÃ¼creyi Ã§evreleyen ve iÃ§eriÄŸi dÄ±ÅŸ ortamdan ayÄ±ran yapÄ±dÄ±r. 
Fosfolipid Ã§ift katmanÄ±ndan oluÅŸur ve seÃ§ici geÃ§irgendir.

---

[BÄ°LGÄ° TABANI #2]
HÃ¼cre ZarÄ±: HÃ¼crenin dÄ±ÅŸ sÄ±nÄ±rÄ±nÄ± oluÅŸturan, fosfolipid Ã§ift katmanlÄ± yapÄ±. 
SeÃ§ici geÃ§irgenlik Ã¶zelliÄŸi ile madde alÄ±ÅŸveriÅŸini kontrol eder.

---

[SORU-CEVAP #3]
HÃ¼cre zarÄ±, hÃ¼creyi Ã§evreleyen ve iÃ§eriÄŸi koruyan yapÄ±dÄ±r.
```

### 2.3. AdÄ±m 3: LLM Prompt Engineering

**AmaÃ§:** LLM'e net ve etkili talimatlar verme

**Fonksiyon:** `generate_answer_with_llm()`

#### 2.3.1. Prompt YapÄ±sÄ±

**BileÅŸenler:**

1. **Course Scope Validation (Ders KapsamÄ± KontrolÃ¼)**
   ```python
   course_scope_section = f"""
   âš ï¸ Ã‡OK Ã–NEMLÄ° - Ä°LK KONTROL (DERS KAPSAMI):
   ÅU ANDA '{session_name}' DERSÄ° Ä°Ã‡Ä°N CEVAP VERÄ°YORSUN.
   
   ğŸ”´ KRÄ°TÄ°K KURAL:
   - Soru ders kapsamÄ± dÄ±ÅŸÄ±ndaysa: 'Bu soru {session_name} dersi kapsamÄ± dÄ±ÅŸÄ±ndadÄ±r.'
   - SADECE ders konularÄ±yla ilgili sorulara cevap ver
   """
   ```

2. **System Role (Sistem RolÃ¼)**
   ```
   Sen bir eÄŸitim asistanÄ±sÄ±n.
   ```

3. **Topic Context (Konu BaÄŸlamÄ±)**
   ```
   ğŸ“š KONU: {topic_title}
   ```

4. **Materials Section (Materyal BÃ¶lÃ¼mÃ¼)**
   ```
   ğŸ“– DERS MATERYALLERÄ° VE BÄ°LGÄ° TABANI:
   {context}
   ```

5. **Student Question (Ã–ÄŸrenci Sorusu)**
   ```
   ğŸ‘¨â€ğŸ“ Ã–ÄRENCÄ° SORUSU:
   {query}
   ```

6. **Answer Rules (Cevap KurallarÄ±)**
   ```
   YANIT KURALLARI (Ã‡OK Ã–NEMLÄ°):
   1. YanÄ±t TAMAMEN TÃœRKÃ‡E olmalÄ±
   2. Sadece sorulan soruya odaklan
   3. En fazla 3 paragraf, 5-8 cÃ¼mle
   4. En fazla 1 gerÃ§ek hayat Ã¶rneÄŸi
   5. Bilgiyi ders materyalinden al, uydurma
   6. Cevap yoksa: 'Bu bilgi ders dÃ¶kÃ¼manlarÄ±nda bulunamamÄ±ÅŸtÄ±r.'
   7. Ã–nemli kavramlarÄ± **kalÄ±n** ile vurgula
   ```

#### 2.3.2. Tam Prompt Ã–rneÄŸi

```python
prompt = f"""{course_scope_section}Sen bir eÄŸitim asistanÄ±sÄ±n. AÅŸaÄŸÄ±daki ders materyallerini kullanarak Ã–ÄRENCÄ° SORUSUNU kÄ±sa, net ve konu dÄ±ÅŸÄ±na Ã§Ä±kmadan yanÄ±tla.

{f"ğŸ“š KONU: {topic_title}" if topic_title else ""}

ğŸ“– DERS MATERYALLERÄ° VE BÄ°LGÄ° TABANI:
{context}

ğŸ‘¨â€ğŸ“ Ã–ÄRENCÄ° SORUSU:
{query}

YANIT KURALLARI (Ã‡OK Ã–NEMLÄ°):
1. YanÄ±t TAMAMEN TÃœRKÃ‡E olmalÄ±.
2. Sadece sorulan soruya odaklan; konu dÄ±ÅŸÄ±na Ã§Ä±kma, gereksiz alt baÅŸlÄ±klar aÃ§ma.
3. YanÄ±tÄ±n toplam uzunluÄŸunu en fazla 3 paragraf ve yaklaÅŸÄ±k 5â€“8 cÃ¼mle ile sÄ±nÄ±rla.
4. Gerekirse en fazla 1 tane kÄ±sa gerÃ§ek hayat Ã¶rneÄŸi ver; uzun anlatÄ±mlardan kaÃ§Ä±n.
5. Bilgiyi mutlaka yukarÄ±daki ders materyali ve bilgi tabanÄ±ndan al; emin olmadÄ±ÄŸÄ±n ÅŸeyleri yazma, uydurma.
6. ğŸ”´ Ã‡OK Ã–NEMLÄ° - EÄŸer sorunun cevabÄ± ders materyallerinde yoksa veya materyaller soruyla ilgili deÄŸilse:
   - SADECE ÅŸu cÃ¼mleyi yaz: 'Bu bilgi ders dÃ¶kÃ¼manlarÄ±nda bulunamamÄ±ÅŸtÄ±r.'
   - BAÅKA HÄ°Ã‡BÄ°R ÅEY EKLEME, aÃ§Ä±klama yapma, Ã¶rnek verme, baÅŸka bilgi verme
   - SADECE bu cÃ¼mleyi yaz ve bitir
7. Ã–nemli kavramlarÄ± gerektiÄŸinde **kalÄ±n** yazarak vurgulayabilirsin ama liste/rapor formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rme.

âœï¸ YANIT (sadece cevabÄ± yaz, baÅŸlÄ±k veya madde listesi ekleme):"""
```

### 2.4. AdÄ±m 4: LLM Generation

**API Endpoint:** `POST /models/generate`

**Request Format:**
```json
{
    "prompt": "{full_prompt}",
    "model": "llama-3.1-8b-instant",
    "max_tokens": 768,
    "temperature": 0.6
}
```

**Model SeÃ§imi:**
- **VarsayÄ±lan**: Groq `llama-3.1-8b-instant` (hÄ±zlÄ±)
- **TÃ¼rkÃ§e OdaklÄ±**: Alibaba `qwen-max` veya `qwen-turbo`
- **YÃ¼ksek Kalite**: Groq `llama-3.3-70b-versatile`

**Parametreler:**
- **max_tokens**: 768 (varsayÄ±lan), 2048 (uzun cevaplar iÃ§in)
- **temperature**: 0.6 (varsayÄ±lan), 0.7 (yaratÄ±cÄ±lÄ±k iÃ§in)

**Response Format:**
```json
{
    "response": "Cevap metni...",
    "model_used": "llama-3.1-8b-instant"
}
```

**SÃ¼re:** 1000-3000ms (model'e baÄŸlÄ±)

### 2.5. AdÄ±m 5: Answer Post-Processing

**AmaÃ§:** LLM Ã§Ä±ktÄ±sÄ±nÄ± temizleme ve formatlama

**Ä°ÅŸlemler:**
1. **Whitespace Temizleme**: Gereksiz boÅŸluklarÄ± kaldÄ±rma
2. **Markdown Formatting**: KalÄ±n yazÄ±larÄ± koruma
3. **CÃ¼mle DÃ¼zeltme**: Eksik noktalama iÅŸaretleri ekleme
4. **Uzunluk KontrolÃ¼**: Ã‡ok uzun cevaplarÄ± kÄ±saltma

**Ã–rnek:**
```python
# Raw LLM output
raw = "HÃ¼cre zarÄ± hÃ¼creyi Ã§evreleyen yapÄ±dÄ±r Fosfolipid Ã§ift katmanÄ±ndan oluÅŸur"

# Post-processed
cleaned = "HÃ¼cre zarÄ±, hÃ¼creyi Ã§evreleyen yapÄ±dÄ±r. Fosfolipid Ã§ift katmanÄ±ndan oluÅŸur."
```

### 2.6. AdÄ±m 6: Personalization (Opsiyonel)

**AmaÃ§:** Ã–ÄŸrenci profiline gÃ¶re cevabÄ± kiÅŸiselleÅŸtirme

**KoÅŸul:** EBARS veya CACS aktifse

**SÃ¼reÃ§:**
1. **Student Profile Analysis**: Ã–ÄŸrenci profilini analiz etme
2. **Pedagogical Analysis**: ZPD, Bloom, Cognitive Load analizi
3. **Personalization Prompt**: KiÅŸiselleÅŸtirme prompt'u oluÅŸturma
4. **LLM Re-generation**: KiÅŸiselleÅŸtirilmiÅŸ cevap Ã¼retimi

**Detaylar:** `PEDAGOJIK_MONITORLER_DETAYLI.md` dosyasÄ±nda

---

## 3. KullanÄ±lan Teknolojiler

### 3.1. LLM Modelleri

| Model | Provider | KullanÄ±m Senaryosu | SÃ¼re | TÃ¼rkÃ§e Kalite |
|-------|----------|-------------------|------|---------------|
| `llama-3.1-8b-instant` | Groq | VarsayÄ±lan, hÄ±zlÄ± cevaplar | 1000-2000ms | â­â­â­ |
| `qwen-max` | Alibaba | TÃ¼rkÃ§e odaklÄ±, yÃ¼ksek kalite | 2000-4000ms | â­â­â­â­â­ |
| `qwen-turbo` | Alibaba | TÃ¼rkÃ§e, hÄ±zlÄ± | 1500-3000ms | â­â­â­â­ |
| `llama-3.3-70b-versatile` | Groq | YÃ¼ksek kalite, Ä°ngilizce | 2000-4000ms | â­â­â­ |
| `deepseek-chat` | DeepSeek | DÃ¼ÅŸÃ¼k maliyet | 1500-3000ms | â­â­â­ |

### 3.2. Prompt Engineering Teknikleri

#### 3.2.1. Few-Shot Learning

**KullanÄ±m:** Ã–rnek cevaplar ile LLM'e rehberlik

**Ã–rnek:**
```
Ã–RNEK SORU: "DNA nedir?"
Ã–RNEK CEVAP: "DNA, genetik bilgiyi taÅŸÄ±yan molekÃ¼ldÃ¼r..."

Ã–ÄRENCÄ° SORUSU: {query}
```

#### 3.2.2. Chain-of-Thought (CoT)

**KullanÄ±m:** AdÄ±m adÄ±m dÃ¼ÅŸÃ¼nme sÃ¼recini yÃ¶nlendirme

**Ã–rnek:**
```
1. Ã–nce ders materyallerini incele
2. Soruyu anla
3. Ä°lgili bilgileri bul
4. CevabÄ± oluÅŸtur
```

#### 3.2.3. Role-Based Prompting

**KullanÄ±m:** LLM'e rol verme

**Ã–rnek:**
```
Sen bir eÄŸitim asistanÄ±sÄ±n.
Ã–ÄŸrencilere yardÄ±mcÄ± olmak iÃ§in buradasÄ±n.
```

#### 3.2.4. Constraint-Based Prompting

**KullanÄ±m:** SÄ±nÄ±rlamalar ve kurallar belirleme

**Ã–rnek:**
```
- En fazla 3 paragraf
- Sadece TÃ¼rkÃ§e
- Ders materyalinden bilgi al
```

### 3.3. Context Management

**Teknoloji:** String concatenation ve length management

**Strateji:**
- KaynaklarÄ± Ã¶ncelik sÄ±rasÄ±na gÃ¶re ekleme
- Maksimum uzunluk kontrolÃ¼ (8000 karakter)
- Kaynak etiketleme

**Optimizasyon:**
- KB iÃ§eriÄŸi tam gÃ¶nderilir (truncation yok)
- Chunk iÃ§eriÄŸi 200 karaktere kadar truncate edilir
- QA iÃ§eriÄŸi tam gÃ¶nderilir

---

## 4. Ã–rnek Soru-Cevap SenaryolarÄ±

### 4.1. Senaryo 1: Basit Bilgi Sorusu

**Ã–ÄŸrenci Sorusu:**
```
"HÃ¼cre zarÄ±nÄ±n yapÄ±sÄ± nedir?"
```

**SÃ¼reÃ§:**

1. **Topic Classification:**
   - Konu: "HÃ¼cre ZarÄ±"
   - Confidence: 0.95

2. **Retrieval:**
   - Chunk: 3 adet (scores: 0.87, 0.82, 0.79)
   - KB: 1 adet (topic summary, score: 0.95)
   - QA: 0 adet (direkt eÅŸleÅŸme yok)

3. **Context Building:**
   ```
   [DERS MATERYALÄ° #1]
   HÃ¼cre zarÄ±, hÃ¼creyi Ã§evreleyen ve iÃ§eriÄŸi dÄ±ÅŸ ortamdan ayÄ±ran yapÄ±dÄ±r. 
   Fosfolipid Ã§ift katmanÄ±ndan oluÅŸur ve seÃ§ici geÃ§irgendir.
   
   ---
   
   [BÄ°LGÄ° TABANI #2]
   HÃ¼cre ZarÄ±: HÃ¼crenin dÄ±ÅŸ sÄ±nÄ±rÄ±nÄ± oluÅŸturan, fosfolipid Ã§ift katmanlÄ± yapÄ±. 
   SeÃ§ici geÃ§irgenlik Ã¶zelliÄŸi ile madde alÄ±ÅŸveriÅŸini kontrol eder.
   ```

4. **LLM Generation:**
   - Model: Groq `llama-3.1-8b-instant`
   - SÃ¼re: 1200ms
   - Temperature: 0.6

5. **Cevap:**
   ```
   HÃ¼cre zarÄ±, hÃ¼creyi Ã§evreleyen ve iÃ§eriÄŸi dÄ±ÅŸ ortamdan ayÄ±ran Ã¶nemli bir yapÄ±dÄ±r. 
   **Fosfolipid Ã§ift katmanÄ±ndan** oluÅŸur ve bu yapÄ± sayesinde seÃ§ici geÃ§irgenlik 
   Ã¶zelliÄŸi gÃ¶sterir. Bu Ã¶zellik, hÃ¼crenin madde alÄ±ÅŸveriÅŸini kontrol etmesini saÄŸlar.
   ```

**Toplam SÃ¼re:** ~2.5 saniye

**Kaynaklar:**
- ğŸ“„ Biyoloji Ders NotlarÄ± #3 (s.12) - Score: 0.87
- ğŸ“š Bilgi TabanÄ± - HÃ¼cre ZarÄ± - Score: 0.95

### 4.2. Senaryo 2: Direkt QA EÅŸleÅŸmesi (En HÄ±zlÄ±)

**Ã–ÄŸrenci Sorusu:**
```
"Mitokondri nedir?"
```

**SÃ¼reÃ§:**

1. **Topic Classification:**
   - Konu: "Mitokondri"
   - Confidence: 0.98

2. **QA Matching:**
   - Similarity: 0.95 â†’ **Direkt eÅŸleÅŸme!**
   - LLM generation atlanÄ±r

3. **Direkt Cevap:**
   ```
   Mitokondri, hÃ¼crenin enerji Ã¼retim merkezidir. ATP (adenozin trifosfat) 
   Ã¼retiminden sorumludur ve hÃ¼crenin enerji ihtiyacÄ±nÄ± karÅŸÄ±lar.
   ```

4. **KB Summary Eklendi:**
   ```
   ğŸ’¡ Ek Bilgi: Mitokondri, hÃ¼crenin enerji Ã¼retiminden sorumlu organeldir...
   ```

**Toplam SÃ¼re:** ~0.8 saniye (LLM generation yok!)

**Kaynaklar:**
- â“ Soru BankasÄ± - Score: 0.95
- ğŸ“š Bilgi TabanÄ± - Mitokondri - Score: 0.98

### 4.3. Senaryo 3: Kompleks Sorgu (Uzun Cevap)

**Ã–ÄŸrenci Sorusu:**
```
"DNA replikasyonu sÃ¼recini detaylÄ± aÃ§Ä±kla ve hÃ¼cre bÃ¶lÃ¼nmesi ile iliÅŸkisini anlat."
```

**SÃ¼reÃ§:**

1. **Topic Classification:**
   - Konu: "DNA Replikasyonu", "HÃ¼cre BÃ¶lÃ¼nmesi"
   - Confidence: 0.92

2. **Retrieval:**
   - Chunk: 10 adet (scores: 0.92-0.81)
   - KB: 2 adet (DNA Replikasyonu, HÃ¼cre BÃ¶lÃ¼nmesi)
   - QA: 1 adet (score: 0.85)

3. **Reranking:**
   - Alibaba Reranker ile sÄ±ralama
   - Top 5 chunk seÃ§ildi

4. **Context Building:**
   - Context uzunluÄŸu: 7500 karakter
   - 5 chunk + 2 KB + 1 QA

5. **LLM Generation:**
   - Model: Alibaba `qwen-max` (TÃ¼rkÃ§e optimize)
   - SÃ¼re: 2800ms
   - Max tokens: 2048
   - Temperature: 0.7

6. **Cevap:**
   ```
   DNA replikasyonu, hÃ¼cre bÃ¶lÃ¼nmesi Ã¶ncesinde gerÃ§ekleÅŸen kritik bir sÃ¼reÃ§tir. 
   Bu sÃ¼reÃ§te, DNA Ã§ift sarmalÄ± aÃ§Ä±lÄ±r ve her bir iplik yeni bir eÅŸ iplik 
   oluÅŸturur. BÃ¶ylece, bÃ¶lÃ¼nen hÃ¼creler aynÄ± genetik bilgiye sahip olur.
   
   HÃ¼cre bÃ¶lÃ¼nmesi ile iliÅŸkisi ÅŸÃ¶yledir: Mitoz bÃ¶lÃ¼nme Ã¶ncesinde DNA 
   replikasyonu gerÃ§ekleÅŸir. Bu sayede, her yeni hÃ¼cre tam bir genetik 
   kopyaya sahip olur. Replikasyon olmadan hÃ¼cre bÃ¶lÃ¼nmesi gerÃ§ekleÅŸemez.
   ```

**Toplam SÃ¼re:** ~6.5 saniye

**Kaynaklar:**
- ğŸ“„ Biyoloji Ders NotlarÄ± #7 (s.25) - Score: 0.92
- ğŸ“š Bilgi TabanÄ± - DNA Replikasyonu - Score: 0.88
- ğŸ“„ Biyoloji Ders NotlarÄ± #9 (s.26) - Score: 0.85

### 4.4. Senaryo 4: KiÅŸiselleÅŸtirilmiÅŸ Cevap (EBARS Aktif)

**Ã–ÄŸrenci Sorusu:**
```
"Fotosentez nasÄ±l Ã§alÄ±ÅŸÄ±r?"
```

**Ã–ÄŸrenci Profili:**
- ZPD: "intermediate"
- Bloom: "understand"
- Cognitive Load: "medium"
- Comprehension Score: 0.65

**SÃ¼reÃ§:**

1. **Hybrid RAG Query:**
   - Cevap Ã¼retildi (normal yol)

2. **APRAG Adaptive Query:**
   - EBARS aktif â†’ KiÅŸiselleÅŸtirme

3. **Pedagogical Analysis:**
   - ZPD: Intermediate â†’ Orta seviye aÃ§Ä±klama
   - Bloom: Understand â†’ Kavramsal aÃ§Ä±klama
   - Cognitive Load: Medium â†’ Orta karmaÅŸÄ±klÄ±k

4. **Personalization Prompt:**
   ```
   ğŸ“Š Ã–ÄRENCÄ° PROFÄ°LÄ°:
   - Anlama Seviyesi: intermediate
   - Zorluk Seviyesi: intermediate
   - AÃ§Ä±klama Stili: balanced
   
   ğŸ¯ ZPD: intermediate â†’ intermediate
   ğŸ§  Bloom: understand (Seviye 2)
   âš–ï¸ BiliÅŸsel YÃ¼k: medium
   
   ğŸ”§ KÄ°ÅÄ°SELLEÅTÄ°RME TALÄ°MATLARI:
   - Orta seviye aÃ§Ä±klama yap
   - Kavramsal aÃ§Ä±klama (Bloom: understand)
   - Orta karmaÅŸÄ±klÄ±k (cognitive load: medium)
   ```

5. **KiÅŸiselleÅŸtirilmiÅŸ Cevap:**
   ```
   Fotosentez, bitkilerin gÃ¼neÅŸ Ä±ÅŸÄ±ÄŸÄ±nÄ± kullanarak besin Ã¼retme sÃ¼recidir. 
   Bu sÃ¼reÃ§, **klorofil** adÄ± verilen pigment sayesinde gerÃ§ekleÅŸir. 
   Bitkiler, karbondioksit ve suyu kullanarak glikoz (ÅŸeker) Ã¼retir.
   
   Basit bir Ã¶rnek: Bir bitki, gÃ¼neÅŸ Ä±ÅŸÄ±ÄŸÄ± altÄ±nda bÃ¼yÃ¼rken aslÄ±nda 
   fotosentez yapÄ±yordur. Bu sÃ¼reÃ§, bitkinin enerji ihtiyacÄ±nÄ± karÅŸÄ±lar.
   ```

**Toplam SÃ¼re:** ~4.2 saniye

**KiÅŸiselleÅŸtirme:**
- ZPD: Intermediate â†’ Orta seviye aÃ§Ä±klama
- Bloom: Understand â†’ Kavramsal aÃ§Ä±klama
- Cognitive Load: Medium â†’ Orta karmaÅŸÄ±klÄ±k
- Ã–rnek eklendi (comprehension score dÃ¼ÅŸÃ¼k)

### 4.5. Senaryo 5: Ders KapsamÄ± DÄ±ÅŸÄ± Soru

**Ã–ÄŸrenci Sorusu:**
```
"Roma'yÄ± kim yaktÄ±?"
```

**Ders:** "BiliÅŸim Teknolojilerinin Temelleri"

**SÃ¼reÃ§:**

1. **Course Scope Validation:**
   - Soru ders kapsamÄ± dÄ±ÅŸÄ±nda (tarih sorusu)
   - Prompt'ta kontrol yapÄ±ldÄ±

2. **LLM Response:**
   ```
   Bu soru BiliÅŸim Teknolojilerinin Temelleri dersi kapsamÄ± dÄ±ÅŸÄ±ndadÄ±r. 
   LÃ¼tfen ders konularÄ±yla ilgili sorular sorun.
   ```

**Toplam SÃ¼re:** ~1.2 saniye

**Not:** Ders materyallerine bakÄ±lmadan Ã¶nce kontrol yapÄ±lÄ±r.

### 4.6. Senaryo 6: Bilgi BulunamadÄ±

**Ã–ÄŸrenci Sorusu:**
```
"Kuantum fiziÄŸinin temel prensipleri nelerdir?"
```

**Ders:** "Biyoloji"

**SÃ¼reÃ§:**

1. **Retrieval:**
   - Chunk: 0 adet (ilgili iÃ§erik yok)
   - KB: 0 adet
   - QA: 0 adet

2. **Context Building:**
   - Context boÅŸ veya Ã§ok dÃ¼ÅŸÃ¼k skorlu

3. **LLM Generation:**
   - Prompt'ta "cevap yoksa" kuralÄ± var

4. **Cevap:**
   ```
   Bu bilgi ders dÃ¶kÃ¼manlarÄ±nda bulunamamÄ±ÅŸtÄ±r.
   ```

**Toplam SÃ¼re:** ~1.5 saniye

**Not:** LLM'e ek aÃ§Ä±klama yapmamasÄ± talimatÄ± verilir.

---

## 5. Prompt Engineering DetaylarÄ±

### 5.1. TÃ¼rkÃ§e OptimizasyonlarÄ±

#### 5.1.1. Dil KurallarÄ±

**Zorunlu Kurallar:**
- TÃ¼m cevaplar TÃ¼rkÃ§e olmalÄ±
- TÃ¼rkÃ§e karakterler korunmalÄ± (ÄŸ, Ã¼, ÅŸ, Ä±, Ã¶, Ã§)
- TÃ¼rkÃ§e dil yapÄ±sÄ±na uygun cÃ¼mleler

**Ã–rnek:**
```
âŒ YanlÄ±ÅŸ: "Cell membrane is..."
âœ… DoÄŸru: "HÃ¼cre zarÄ±..."
```

#### 5.1.2. KÃ¼ltÃ¼rel BaÄŸlam

**EÄŸitim Terminolojisi:**
- "Ders" â†’ "lesson" deÄŸil, "course"
- "SÄ±nav" â†’ "exam"
- "Ã–dev" â†’ "homework"

**Ã–ÄŸrenci Dili:**
- GÃ¼nlÃ¼k dil kullanÄ±mÄ±na uyum
- Resmi ve samimi dil dengesi

### 5.2. Cevap FormatÄ± KurallarÄ±

#### 5.2.1. Uzunluk SÄ±nÄ±rlamalarÄ±

**Kurallar:**
- En fazla 3 paragraf
- 5-8 cÃ¼mle
- Maksimum 768 token (varsayÄ±lan)

**Neden:**
- Ã–ÄŸrenci dikkat sÃ¼resi
- Cognitive load yÃ¶netimi
- HÄ±zlÄ± anlama

#### 5.2.2. Ä°Ã§erik KurallarÄ±

**Zorunlular:**
- Sadece sorulan soruya odaklanma
- Ders materyalinden bilgi alma
- Konu dÄ±ÅŸÄ±na Ã§Ä±kmama

**Yasaklar:**
- Uydurma bilgi
- Ders kapsamÄ± dÄ±ÅŸÄ± bilgi
- Gereksiz detaylar

### 5.3. Hata YÃ¶netimi

#### 5.3.1. Bilgi BulunamadÄ±

**Kural:**
```
EÄŸer sorunun cevabÄ± ders materyallerinde yoksa:
- SADECE: 'Bu bilgi ders dÃ¶kÃ¼manlarÄ±nda bulunamamÄ±ÅŸtÄ±r.'
- BAÅKA HÄ°Ã‡BÄ°R ÅEY EKLEME
```

**Neden:**
- HalÃ¼sinasyon Ã¶nleme
- YanlÄ±ÅŸ bilgi vermeme
- Ã–ÄŸrenci gÃ¼veni

#### 5.3.2. Ders KapsamÄ± DÄ±ÅŸÄ±

**Kural:**
```
EÄŸer soru ders kapsamÄ± dÄ±ÅŸÄ±ndaysa:
- 'Bu soru {session_name} dersi kapsamÄ± dÄ±ÅŸÄ±ndadÄ±r.'
```

**Neden:**
- Ders odaklÄ±lÄ±k
- Ä°lgisiz sorularÄ± engelleme
- Ã–ÄŸrenci yÃ¶nlendirme

---

## 6. Performans OptimizasyonlarÄ±

### 6.1. Direct QA Match

**Optimizasyon:**
- Similarity > 0.90 â†’ Direkt cevap
- LLM generation atlanÄ±r
- %80-90 sÃ¼re tasarrufu

**Ã–rnek:**
- Normal yol: 2.5 saniye
- Direct QA: 0.8 saniye
- Tasarruf: %68

### 6.2. Context Optimization

**Strateji:**
- En yÃ¼ksek skorlu kaynaklar Ã¶nce
- KB iÃ§eriÄŸi tam gÃ¶nderilir
- Chunk iÃ§eriÄŸi truncate edilir (200 karakter)

**Etki:**
- Daha az token kullanÄ±mÄ±
- Daha hÄ±zlÄ± generation
- Daha dÃ¼ÅŸÃ¼k maliyet

### 6.3. Model Selection

**Strateji:**
- HÄ±zlÄ± sorular â†’ Groq `llama-3.1-8b-instant`
- TÃ¼rkÃ§e sorular â†’ Alibaba `qwen-max`
- Kompleks sorular â†’ Alibaba `qwen-max` (uzun context)

**Etki:**
- Ortalama sÃ¼re: 2.5 saniye
- TÃ¼rkÃ§e kalite: %40+ artÄ±ÅŸ
- Maliyet: %30-50 azalma

---

## 7. KiÅŸiselleÅŸtirme Entegrasyonu

### 7.1. Personalization Pipeline

**AkÄ±ÅŸ:**
```
Original RAG Response
    â†“
Student Profile Analysis
    â†“
Pedagogical Analysis (ZPD, Bloom, Cognitive Load)
    â†“
Personalization Prompt Generation
    â†“
LLM Re-generation
    â†“
Personalized Response
```

### 7.2. Personalization Prompt YapÄ±sÄ±

**BileÅŸenler:**

1. **Ã–ÄŸrenci Profili:**
   ```
   ğŸ“Š Ã–ÄRENCÄ° PROFÄ°LÄ°:
   - Anlama Seviyesi: intermediate
   - Zorluk Seviyesi: intermediate
   - AÃ§Ä±klama Stili: balanced
   - Ã–rnekler Gerekli: HayÄ±r
   ```

2. **ZPD Bilgisi:**
   ```
   ğŸ¯ ZPD:
   - Mevcut Seviye: intermediate
   - Ã–nerilen Seviye: intermediate
   - BaÅŸarÄ± OranÄ±: 65%
   ```

3. **Bloom Taksonomisi:**
   ```
   ğŸ§  Bloom Taksonomisi:
   - Tespit Edilen Seviye: understand (Seviye 2)
   - GÃ¼ven: 85%
   ```

4. **Cognitive Load:**
   ```
   âš–ï¸ BiliÅŸsel YÃ¼k:
   - Toplam YÃ¼k: 0.65
   - SadeleÅŸtirme Gerekli: HayÄ±r
   ```

5. **KiÅŸiselleÅŸtirme TalimatlarÄ±:**
   ```
   ğŸ”§ KÄ°ÅÄ°SELLEÅTÄ°RME TALÄ°MATLARI:
   - Orta seviye aÃ§Ä±klama yap
   - Kavramsal aÃ§Ä±klama (Bloom: understand)
   - Orta karmaÅŸÄ±klÄ±k
   ```

### 7.3. Zorluk Seviyesine GÃ¶re Adaptasyon

**Beginner (Very Struggling):**
```
âš ï¸ Ã–ÄRENME SÃœRECÄ°NDE SEVÄ°YESÄ° - MUTLAKA UYGULA:
- Teknik terimleri MUTLAKA basitleÅŸtir ve aÃ§Ä±kla
- Her teknik terimi gÃ¼nlÃ¼k hayattan Ã¶rnekle aÃ§Ä±kla
- CÃ¼mleleri 12-18 kelime arasÄ±nda tut
- 3-4 somut Ã¶rnek MUTLAKA ver
- Benzetmeler kullan
- Destekleyici dil kullan
- AdÄ±m adÄ±m aÃ§Ä±kla
```

**Intermediate (Normal):**
```
- Orta seviye aÃ§Ä±klama yap
- Dengeli detay seviyesi
- 1-2 Ã¶rnek ver
```

**Advanced (Good/Excellent):**
```
- Daha derinlemesine bilgi ver
- Ä°leri seviye detaylar ekle
- Teknik terimleri kullan
```

---

## 8. Hata SenaryolarÄ± ve Ã‡Ã¶zÃ¼mler

### 8.1. LLM Timeout

**Sorun:** LLM yanÄ±t vermiyor (60 saniye timeout)

**Ã‡Ã¶zÃ¼m:**
- Fallback model kullanÄ±mÄ±
- Timeout artÄ±rma (uzun sorgular iÃ§in)
- Async RAG kullanÄ±mÄ±

### 8.2. HalÃ¼sinasyon (YanlÄ±ÅŸ Bilgi)

**Sorun:** LLM ders materyalinde olmayan bilgi Ã¼retiyor

**Ã‡Ã¶zÃ¼m:**
- Prompt'ta "uydurma" yasaÄŸÄ±
- Context'ten bilgi alma zorunluluÄŸu
- "Emin olmadÄ±ÄŸÄ±n ÅŸeyleri yazma" kuralÄ±
- HalÃ¼sinasyon tespit modelleri (gelecekte)

### 8.3. Ã‡ok Uzun Cevap

**Sorun:** LLM Ã§ok uzun cevap Ã¼retiyor

**Ã‡Ã¶zÃ¼m:**
- Max tokens sÄ±nÄ±rlamasÄ± (768)
- Prompt'ta uzunluk kuralÄ± (3 paragraf, 5-8 cÃ¼mle)
- Post-processing ile kÄ±saltma

### 8.4. Ä°ngilizce Cevap

**Sorun:** LLM Ä°ngilizce cevap veriyor

**Ã‡Ã¶zÃ¼m:**
- Prompt'ta "TAMAMEN TÃœRKÃ‡E" zorunluluÄŸu
- TÃ¼rkÃ§e optimize modeller (Alibaba Qwen)
- Post-processing kontrolÃ¼

---

## 9. Metrikler ve Performans

### 9.1. Cevap Ãœretim SÃ¼releri

| Senaryo | Ortalama SÃ¼re | Notlar |
|---------|---------------|--------|
| **Direct QA Match** | 0.8 saniye | LLM generation yok |
| **Basit Soru** | 2.5 saniye | Groq, kÄ±sa cevap |
| **Kompleks Soru** | 6.5 saniye | Alibaba, uzun cevap |
| **KiÅŸiselleÅŸtirilmiÅŸ** | 4.2 saniye | Ä°ki LLM Ã§aÄŸrÄ±sÄ± |

### 9.2. Cevap Kalitesi Metrikleri

| Metrik | Hedef | Ã–lÃ§Ã¼m |
|--------|-------|-------|
| **DoÄŸruluk** | %90+ | HalÃ¼sinasyon tespit |
| **TÃ¼rkÃ§e Uyumu** | %95+ | Dil kontrolÃ¼ |
| **Uzunluk Uyumu** | %85+ | 3 paragraf, 5-8 cÃ¼mle |
| **Kaynak KullanÄ±mÄ±** | %80+ | Ders materyalinden bilgi |

### 9.3. Maliyet Analizi

| Model | 1M Token Maliyeti | Ortalama Cevap Maliyeti |
|-------|-------------------|------------------------|
| Groq `llama-3.1-8b-instant` | $0.10 | $0.0001 |
| Alibaba `qwen-max` | $0.24 | $0.0002 |
| Alibaba `qwen-turbo` | $0.016 | $0.00002 |

---

## 10. Best Practices

### 10.1. Prompt Engineering

1. **Net Talimatlar:**
   - Belirsizlik bÄ±rakmama
   - Ã–rnekler verme
   - KurallarÄ± numaralandÄ±rma

2. **TÃ¼rkÃ§e Optimizasyonu:**
   - TÃ¼rkÃ§e karakterler korunmalÄ±
   - TÃ¼rkÃ§e dil yapÄ±sÄ±na uyum
   - KÃ¼ltÃ¼rel baÄŸlam

3. **Hata Ã–nleme:**
   - "Uydurma" yasaÄŸÄ±
   - "Ders kapsamÄ±" kontrolÃ¼
   - "Bilgi yoksa" kuralÄ±

### 10.2. Model SeÃ§imi

1. **HÄ±z Ã–ncelikli:**
   - Groq `llama-3.1-8b-instant`

2. **TÃ¼rkÃ§e Ã–ncelikli:**
   - Alibaba `qwen-max` veya `qwen-turbo`

3. **Kalite Ã–ncelikli:**
   - Alibaba `qwen-max`
   - Groq `llama-3.3-70b-versatile`

### 10.3. Context Management

1. **Ã–ncelik SÄ±ralamasÄ±:**
   - KB â†’ QA â†’ Chunks

2. **Uzunluk YÃ¶netimi:**
   - KB: Tam iÃ§erik
   - Chunks: 200 karakter truncate
   - QA: Tam iÃ§erik

3. **Kaynak Ã‡eÅŸitliliÄŸi:**
   - Her kaynak tipinden en az 1 adet

---

## 11. SonuÃ§

Cevap Ã¼retim sistemi, hybrid RAG mimarisi Ã¼zerine kurulmuÅŸ, LLM tabanlÄ± bir sistemdir. Prompt engineering, context management ve personalization teknikleri ile Ã¶ÄŸrencilere doÄŸru, anlaÅŸÄ±lÄ±r ve kiÅŸiselleÅŸtirilmiÅŸ cevaplar sunmaktadÄ±r.

**Temel Ã–zellikler:**
- Hybrid retrieval (Chunks + KB + QA)
- TÃ¼rkÃ§e optimize prompt engineering
- KiÅŸiselleÅŸtirilmiÅŸ cevap Ã¼retimi
- Hata yÃ¶netimi ve halÃ¼sinasyon Ã¶nleme
- Performans optimizasyonlarÄ±

**BaÅŸarÄ± FaktÃ¶rleri:**
- DoÄŸru bilgi kaynaklarÄ±
- Etkili prompt engineering
- Uygun model seÃ§imi
- KiÅŸiselleÅŸtirme entegrasyonu

---

**HazÄ±rlanma Tarihi**: 2025-12-05
**Durum**: Cevap Ãœretim Sistemi DetaylÄ± DokÃ¼mantasyonu
**Versiyon**: 1.0


