# Student Chat Sistemi: DetaylÄ± Ã‡alÄ±ÅŸma MekanizmasÄ± ve Model KullanÄ±mÄ±

## 1. Genel BakÄ±ÅŸ

Student Chat sistemi, Ã¶ÄŸrencilerin ders materyalleri hakkÄ±nda soru sorabileceÄŸi ve kiÅŸiselleÅŸtirilmiÅŸ cevaplar alabileceÄŸi bir AI asistanÄ±dÄ±r. Sistem, Hybrid RAG (Retrieval-Augmented Generation) mimarisi Ã¼zerine kurulmuÅŸtur ve Ã§oklu model desteÄŸi, akÄ±llÄ± kaynak seÃ§imi ve performans optimizasyonlarÄ± iÃ§erir.

### 1.1. Sistem Mimarisi

```
Frontend (Student Chat Page)
    â†“
useStudentChat Hook
    â†“
Hybrid RAG Query API
    â†“
â”œâ”€â”€ Topic Classification (LLM)
â”œâ”€â”€ Chunk Retrieval (Vector Search)
â”œâ”€â”€ Knowledge Base Retrieval (SQL)
â”œâ”€â”€ QA Pair Matching (Similarity)
â””â”€â”€ Reranking (Alibaba Reranker)
    â†“
LLM Generation (Groq/Alibaba/OpenRouter)
    â†“
APRAG Adaptive Query (KiÅŸiselleÅŸtirme)
    â†“
Response + Sources + Metadata
```

---

## 2. Model SeÃ§imi ve YapÄ±landÄ±rmasÄ±

### 2.1. Model SeÃ§im HiyerarÅŸisi

**Ã–ncelik SÄ±rasÄ±:**
1. **Request Model**: KullanÄ±cÄ± tarafÄ±ndan belirtilen model (varsa)
2. **Session RAG Settings**: Session'a Ã¶zel model ayarlarÄ±
3. **VarsayÄ±lan Model**: `llama-3.1-8b-instant` (Groq)

**Kod Ã–rneÄŸi:**
```typescript
// useStudentChat.ts
const effective_model = request.model 
    || sessionRagSettings?.model 
    || "llama-3.1-8b-instant";
```

### 2.2. Embedding Model SeÃ§imi

**Kritik Nokta:** Embedding model, ChromaDB collection'Ä±n boyutuna uygun olmalÄ±dÄ±r.

**SeÃ§im MantÄ±ÄŸÄ±:**
1. **Session RAG Settings**: Session'a Ã¶zel embedding model
2. **VarsayÄ±lan**: `text-embedding-v4` (Alibaba DashScope)

**KullanÄ±m:**
```typescript
// useStudentChat.ts - Line 198
embedding_model: sessionRagSettings?.embedding_model, 
// CRITICAL: Match collection's embedding model
```

**Neden Ã–nemli?**
- FarklÄ± embedding modelleri farklÄ± boyutlarda vektÃ¶rler Ã¼retir
- ChromaDB collection'Ä± belirli bir boyut iÃ§in oluÅŸturulur
- Boyut uyuÅŸmazlÄ±ÄŸÄ± retrieval hatalarÄ±na neden olur

**Desteklenen Embedding Modelleri:**
- `text-embedding-v4` (Alibaba) - 1024 boyut, varsayÄ±lan
- `nomic-embed-text` (Ollama) - 768 boyut
- `sentence-transformers/all-MiniLM-L6-v2` (HuggingFace) - 384 boyut

### 2.3. Reranker Model SeÃ§imi

**KullanÄ±lan Model:** Alibaba DashScope Reranker

**Neden Alibaba Reranker?**
- **TÃ¼rkÃ§e Optimizasyonu**: TÃ¼rkÃ§e metinler iÃ§in Ã¶zel eÄŸitim
- **YÃ¼ksek Performans**: Cross-encoder mimarisi ile daha doÄŸru sÄ±ralama
- **DÃ¼ÅŸÃ¼k Maliyet**: API tabanlÄ±, yerel iÅŸlem gerektirmez
- **HÄ±z**: Yerel reranker'lara gÃ¶re daha hÄ±zlÄ±

**KullanÄ±m Senaryosu:**
```python
# hybrid_rag_query.py - Line 586
if request.use_crag and chunk_results:
    rerank_result = await rerank_documents(request.query, chunk_results)
    # Rerank edilmiÅŸ chunk'larÄ± kullan
    chunk_results = reranked_chunks[:request.top_k]
```

**Reranker Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±:**
1. Ä°lk retrieval: `top_k * 2` chunk alÄ±nÄ±r (daha fazla seÃ§enek)
2. Reranking: Alibaba reranker ile sÄ±ralama
3. Final selection: En Ã¼stteki `top_k` chunk seÃ§ilir

**Avantajlar:**
- Daha doÄŸru kaynak seÃ§imi
- Ä°lgisiz chunk'larÄ±n filtrelenmesi
- Cevap kalitesinde artÄ±ÅŸ

---

## 3. Sorgu ve Cevaplama SÃ¼reci

### 3.1. Sorgu AkÄ±ÅŸÄ±

**AdÄ±m 1: KullanÄ±cÄ± Sorgusu**
```typescript
// Student Chat Page - handleSendMessage
const startTime = Date.now();
await sendMessage(query, sessionRagSettings);
```

**AdÄ±m 2: Hybrid RAG Query**
```typescript
// useStudentChat.ts - Line 245
const result = await hybridRAGQuery({
    session_id: sessionId,
    query: query,
    top_k: 5,
    use_kb: true,
    use_qa_pairs: true,
    use_crag: true, // Reranking aktif
    model: sessionRagSettings?.model,
    embedding_model: sessionRagSettings?.embedding_model,
    max_tokens: 2048,
    temperature: 0.7,
    max_context_chars: 8000,
    include_examples: true,
    include_sources: true,
    user_id: user?.id?.toString() || "student",
});
```

**AdÄ±m 3: Topic Classification**
- LLM ile konu tespiti
- Keyword-based fallback
- Cache mekanizmasÄ± (7 gÃ¼nlÃ¼k TTL)

**AdÄ±m 4: Retrieval**
- **Chunk Retrieval**: Vector similarity search
- **KB Retrieval**: SQL query ile structured knowledge
- **QA Matching**: Cosine similarity ile direkt cevap

**AdÄ±m 5: Reranking (Opsiyonel)**
- Alibaba reranker ile chunk sÄ±ralamasÄ±
- En Ã¼stteki `top_k` chunk seÃ§imi

**AdÄ±m 6: LLM Generation**
- Context building (chunks + KB + QA)
- LLM ile cevap Ã¼retimi
- Model: Groq/Alibaba/OpenRouter

**AdÄ±m 7: APRAG Personalization (Opsiyonel)**
- EBARS veya CACS aktifse
- KiÅŸiselleÅŸtirilmiÅŸ cevap Ã¼retimi
- ZPD, Bloom, Cognitive Load adaptasyonu

**AdÄ±m 8: Response**
```typescript
const actualDurationMs = Date.now() - startTime;
// Response includes: answer, sources, durationMs, suggestions
```

### 3.2. SÃ¼re Ã–lÃ§Ã¼mÃ¼

**Ã–lÃ§Ã¼len SÃ¼reler:**

| AÅŸama | AÃ§Ä±klama | Ortalama SÃ¼re |
|-------|----------|---------------|
| **Topic Classification** | LLM ile konu tespiti | 500-1500ms |
| **Chunk Retrieval** | Vector search | 100-300ms |
| **KB Retrieval** | SQL query | 50-150ms |
| **QA Matching** | Similarity calculation | 50-200ms |
| **Reranking** | Alibaba reranker | 200-500ms |
| **LLM Generation** | Cevap Ã¼retimi | 1000-3000ms |
| **APRAG Personalization** | KiÅŸiselleÅŸtirme | 500-1500ms |
| **TOPLAM** | TÃ¼m sÃ¼reÃ§ | 2400-7200ms |

**Frontend'de GÃ¶sterim:**
```typescript
// Student Chat Page - Line 773
{message.durationMs && 
  `âš¡ ${(message.durationMs / 1000).toFixed(1)}s`}
```

**Performans OptimizasyonlarÄ±:**
- **Async RAG**: Uzun iÅŸlemler iÃ§in background task
- **Caching**: Topic classification cache (7 gÃ¼n)
- **Batch Processing**: Embedding batch (25 metin)
- **Direct QA Match**: YÃ¼ksek similarity (>0.90) iÃ§in direkt cevap

### 3.3. Async RAG (Uzun Ä°ÅŸlemler)

**KullanÄ±m Senaryosu:**
```typescript
// useStudentChat.ts - Line 214
const estimatedComplexity = query.length + 
    (sessionRagSettings?.chunk_strategy === "semantic" ? 100 : 0);
const useAsyncRAG = estimatedComplexity > 150;
```

**Async RAG AkÄ±ÅŸÄ±:**
1. **Task BaÅŸlatma**: `startAsyncRAGQuery()` ile background task
2. **Progress Tracking**: 2 saniyede bir status kontrolÃ¼
3. **Result Polling**: Task tamamlanana kadar bekleme
4. **Response**: Tamamlanan sonuÃ§ dÃ¶ndÃ¼rÃ¼lÃ¼r

**Progress GÃ¶sterimi:**
```typescript
// Student Chat Page - Line 1056
{asyncTaskProgress ? 
  `ğŸš€ ${asyncTaskProgress.currentStep}` : 
  "ğŸ§  AI AsistanÄ± Cevap HazÄ±rlÄ±yor..."}
```

---

## 4. Kaynak GÃ¶sterimi

### 4.1. Kaynak Tipleri

**3 Ana Kaynak Tipi:**

1. **Chunk (DÃ¶kÃ¼man ParÃ§alarÄ±)**
   - Vector search ile bulunan metin parÃ§alarÄ±
   - Metadata: `filename`, `chunk_index`, `page_number`, `score`
   - GÃ¶sterim: `ğŸ“„ [Dosya AdÄ±] #1, #2, #3...`

2. **Knowledge Base (Bilgi TabanÄ±)**
   - Structured knowledge (topic summary, concepts, objectives)
   - Metadata: `topic_id`, `topic_title`, `relevance_score`
   - GÃ¶sterim: `ğŸ“š Bilgi TabanÄ±`

3. **QA Pairs (Soru BankasÄ±)**
   - Direkt cevap eÅŸleÅŸmeleri
   - Metadata: `qa_id`, `question`, `similarity_score`
   - GÃ¶sterim: `â“ Soru BankasÄ±`

### 4.2. Kaynak Filtreleme

**Min Score Threshold:**
```typescript
// Student Chat Page - Line 369
const minScoreThreshold = sessionRagSettings?.min_score_threshold ?? 0.4;

// Filter sources: only show sources with score >= threshold
const filteredSources = sources.filter((source) => {
    let score = source.score || 0;
    // Normalize if percentage format (0-100) to 0-1
    if (score > 1.0 && score <= 100.0) {
        score = score / 100.0;
    }
    return score >= minScoreThreshold;
});
```

**Filtreleme MantÄ±ÄŸÄ±:**
- VarsayÄ±lan threshold: **0.4 (40%)**
- Session RAG settings'den alÄ±nabilir
- Score normalization: 0-100 formatÄ± 0-1'e Ã§evrilir
- DÃ¼ÅŸÃ¼k skorlu kaynaklar gÃ¶sterilmez

### 4.3. Kaynak Gruplama

**Dosya BazlÄ± Gruplama:**
```typescript
// Student Chat Page - Line 384
const sourceMap = new Map<string, RAGSource[]>();

filteredSources.forEach((source) => {
    const filename = source.metadata?.filename || 
                     source.metadata?.source_file || 
                     "unknown";
    if (!sourceMap.has(filename)) {
        sourceMap.set(filename, []);
    }
    sourceMap.get(filename)!.push(source);
});
```

**GÃ¶sterim FormatÄ±:**
- **Chunk**: `ğŸ“„ [Dosya AdÄ±] #1 (s.5), #2 (s.6)...`
- **KB**: `ğŸ“š Bilgi TabanÄ±`
- **QA**: `â“ Soru BankasÄ±`

### 4.4. Kaynak Detay GÃ¶sterimi

**Source Modal:**
- TÄ±klanabilir kaynak butonlarÄ±
- Modal ile tam iÃ§erik gÃ¶sterimi
- Metadata bilgileri (score, page, chunk index)

**Kaynak Ã–zeti:**
```typescript
// Student Chat Page - Line 712
{(() => {
    const types = getSourceTypes(message.sources);
    const hasKB = types.has("knowledge_base");
    const hasQA = types.has("qa_pair");
    const hasChunks = types.has("chunk") || types.size === 0;
    return (
        <>
            {hasKB && <span>ğŸ“š Bilgi TabanÄ± KullanÄ±ldÄ±</span>}
            {hasQA && <span>â“ Soru BankasÄ±</span>}
            {hasChunks && <span>ğŸ“„ DÃ¶kÃ¼man ParÃ§alarÄ±</span>}
        </>
    );
})()}
```

---

## 5. Bilgi TabanÄ±ndan Kaynak Getirme

### 5.1. Knowledge Base YapÄ±sÄ±

**Tablo: `topic_knowledge_base`**

| SÃ¼tun | Tip | AÃ§Ä±klama |
|-------|-----|----------|
| `topic_id` | INTEGER | Konu ID |
| `topic_title` | TEXT | Konu baÅŸlÄ±ÄŸÄ± |
| `content` | JSON | Structured knowledge (summary, concepts, objectives, examples) |
| `created_at` | TIMESTAMP | OluÅŸturulma tarihi |

**Content JSON YapÄ±sÄ±:**
```json
{
    "topic_summary": "Konu Ã¶zeti...",
    "key_concepts": ["Kavram 1", "Kavram 2"],
    "learning_objectives": ["AmaÃ§ 1", "AmaÃ§ 2"],
    "examples": ["Ã–rnek 1", "Ã–rnek 2"]
}
```

### 5.2. KB Retrieval SÃ¼reci

**AdÄ±m 1: Topic Classification**
```python
# hybrid_knowledge_retriever.py
matched_topics = await _classify_to_topics(
    query=query,
    session_id=session_id
)
```

**AdÄ±m 2: SQL Query**
```python
# hybrid_knowledge_retriever.py
kb_query = """
    SELECT topic_id, topic_title, content
    FROM topic_knowledge_base
    WHERE topic_id IN ({})
    ORDER BY topic_id
""".format(','.join(['?'] * len(matched_topics)))

kb_results = db.execute_query(kb_query, [t['topic_id'] for t in matched_topics])
```

**AdÄ±m 3: Content Parsing**
```python
# hybrid_knowledge_retriever.py
for kb_item in kb_results:
    content_json = json.loads(kb_item['content'])
    kb_data = {
        'topic_id': kb_item['topic_id'],
        'topic_title': kb_item['topic_title'],
        'content': {
            'topic_summary': content_json.get('topic_summary', ''),
            'key_concepts': content_json.get('key_concepts', []),
            'learning_objectives': content_json.get('learning_objectives', []),
            'examples': content_json.get('examples', [])
        },
        'relevance_score': classification_confidence
    }
```

**AdÄ±m 4: Merged Results'a Ekleme**
```python
# hybrid_rag_query.py - Line 627
for kb_item in kb_results:
    merged_results.append({
        "source": "knowledge_base",
        "content": kb_item.get("content", {}).get("topic_summary", ""),
        "score": kb_item.get("relevance_score", 0.0),
        "final_score": kb_item.get("relevance_score", 0.0),
        "metadata": {
            "topic_id": kb_item.get("topic_id"),
            "topic_title": kb_item.get("topic_title", ""),
            "source_type": "knowledge_base",
            "source": "knowledge_base",
            "filename": "unknown"
        }
    })
```

### 5.3. KB KullanÄ±m SenaryolarÄ±

**1. Topic Summary (Konu Ã–zeti)**
- LLM context'ine eklenir
- Cevap Ã¼retiminde kullanÄ±lÄ±r
- Frontend'de "Bilgi TabanÄ±" olarak gÃ¶sterilir

**2. Key Concepts (Anahtar Kavramlar)**
- Context'e eklenebilir
- Ã–rnekler ve aÃ§Ä±klamalar iÃ§in referans

**3. Learning Objectives (Ã–ÄŸrenme Hedefleri)**
- Cevap kalitesini artÄ±rÄ±r
- Hedef odaklÄ± aÃ§Ä±klamalar

**4. Examples (Ã–rnekler)**
- Context'e eklenebilir
- Somut Ã¶rneklerle aÃ§Ä±klama

### 5.4. KB AvantajlarÄ±

**Structured Knowledge:**
- DÃ¼zenli, yapÄ±landÄ±rÄ±lmÄ±ÅŸ bilgi
- LLM iÃ§in optimize edilmiÅŸ format
- HÄ±zlÄ± eriÅŸim (SQL query)

**Kalite:**
- LLM ile Ã§Ä±karÄ±lmÄ±ÅŸ, doÄŸrulanmÄ±ÅŸ bilgi
- Topic bazlÄ± organize
- Relevance scoring

**Performans:**
- SQL query ile hÄ±zlÄ± eriÅŸim
- Cache mekanizmasÄ± (topic classification)
- Vector search'e gÃ¶re daha hÄ±zlÄ±

---

## 6. Pratik KullanÄ±m SenaryolarÄ±

### 6.1. Basit Sorgu (HÄ±zlÄ± Cevap)

**Sorgu:** "HÃ¼cre zarÄ±nÄ±n yapÄ±sÄ± nedir?"

**AkÄ±ÅŸ:**
1. Topic Classification: "HÃ¼cre ZarÄ±" â†’ 0.95 confidence
2. Chunk Retrieval: 5 chunk bulundu
3. KB Retrieval: Topic summary bulundu
4. QA Matching: Direkt cevap yok
5. Reranking: 5 chunk sÄ±ralandÄ±
6. LLM Generation: Groq `llama-3.1-8b-instant` (1000ms)
7. **Toplam SÃ¼re:** ~2.5 saniye

**Kaynaklar:**
- ğŸ“„ Biyoloji Ders NotlarÄ± #3 (s.12) - Score: 0.87
- ğŸ“š Bilgi TabanÄ± - HÃ¼cre ZarÄ± - Score: 0.95
- ğŸ“„ Biyoloji Ders NotlarÄ± #5 (s.13) - Score: 0.82

### 6.2. Kompleks Sorgu (Async RAG)

**Sorgu:** "DNA replikasyonu sÃ¼recini detaylÄ± aÃ§Ä±kla ve hÃ¼cre bÃ¶lÃ¼nmesi ile iliÅŸkisini anlat."

**AkÄ±ÅŸ:**
1. Complexity Check: 150+ karakter â†’ Async RAG
2. Task BaÅŸlatma: Background task oluÅŸturuldu
3. Progress Tracking: "DÃ¶kÃ¼manlar analiz ediliyor..." (0%)
4. Retrieval: 10 chunk, 2 KB item, 1 QA pair
5. Reranking: 10 chunk sÄ±ralandÄ±
6. LLM Generation: Alibaba `qwen-max` (2500ms)
7. **Toplam SÃ¼re:** ~8 saniye

**Kaynaklar:**
- ğŸ“„ Biyoloji Ders NotlarÄ± #7 (s.25) - Score: 0.92
- ğŸ“š Bilgi TabanÄ± - DNA Replikasyonu - Score: 0.88
- ğŸ“„ Biyoloji Ders NotlarÄ± #9 (s.26) - Score: 0.85
- ğŸ“„ Biyoloji Ders NotlarÄ± #12 (s.28) - Score: 0.81

### 6.3. Direkt QA EÅŸleÅŸmesi (En HÄ±zlÄ±)

**Sorgu:** "Mitokondri nedir?"

**AkÄ±ÅŸ:**
1. Topic Classification: "Mitokondri" â†’ 0.98 confidence
2. QA Matching: Similarity 0.95 â†’ Direkt cevap bulundu!
3. **Direkt Cevap:** "Mitokondri, hÃ¼crenin enerji Ã¼retim merkezidir..."
4. KB Summary eklendi
5. **Toplam SÃ¼re:** ~0.8 saniye (LLM generation yok!)

**Kaynaklar:**
- â“ Soru BankasÄ± - Score: 0.95
- ğŸ“š Bilgi TabanÄ± - Mitokondri - Score: 0.98

### 6.4. KiÅŸiselleÅŸtirilmiÅŸ Cevap (EBARS Aktif)

**Sorgu:** "Fotosentez nasÄ±l Ã§alÄ±ÅŸÄ±r?"

**AkÄ±ÅŸ:**
1. Hybrid RAG Query: Cevap Ã¼retildi
2. APRAG Adaptive Query: EBARS aktif â†’ KiÅŸiselleÅŸtirme
3. Student Profile: ZPD = "intermediate", Bloom = "understand"
4. Personalized Response: Seviyeye uygun aÃ§Ä±klama
5. **Toplam SÃ¼re:** ~4 saniye

**Kaynaklar:**
- ğŸ“„ Biyoloji Ders NotlarÄ± #15 (s.35) - Score: 0.89
- ğŸ“š Bilgi TabanÄ± - Fotosentez - Score: 0.91

**KiÅŸiselleÅŸtirme:**
- ZPD: Intermediate â†’ Orta seviye aÃ§Ä±klama
- Bloom: Understand â†’ Kavramsal aÃ§Ä±klama
- Cognitive Load: Medium â†’ Orta karmaÅŸÄ±klÄ±k

---

## 7. Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

### 7.1. LLM Modelleri (Cevap Ãœretimi)

| Model | Provider | Ortalama SÃ¼re | TÃ¼rkÃ§e Kalite | Maliyet | KullanÄ±m Senaryosu |
|-------|----------|---------------|---------------|---------|-------------------|
| `llama-3.1-8b-instant` | Groq | 1000-2000ms | â­â­â­ | â­â­â­â­â­ | VarsayÄ±lan, hÄ±zlÄ± cevaplar |
| `qwen-max` | Alibaba | 2000-4000ms | â­â­â­â­â­ | â­â­â­â­ | TÃ¼rkÃ§e odaklÄ±, yÃ¼ksek kalite |
| `qwen-turbo` | Alibaba | 1500-3000ms | â­â­â­â­ | â­â­â­â­â­ | TÃ¼rkÃ§e, hÄ±zlÄ± |
| `llama-3.3-70b-versatile` | Groq | 2000-4000ms | â­â­â­ | â­â­â­â­ | YÃ¼ksek kalite, Ä°ngilizce |
| `deepseek-chat` | DeepSeek | 1500-3000ms | â­â­â­ | â­â­â­â­â­ | DÃ¼ÅŸÃ¼k maliyet |

### 7.2. Embedding Modelleri

| Model | Provider | Boyut | TÃ¼rkÃ§e DesteÄŸi | HÄ±z | Maliyet |
|-------|----------|-------|----------------|-----|---------|
| `text-embedding-v4` | Alibaba | 1024 | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ |
| `nomic-embed-text` | Ollama | 768 | â­â­â­ | â­â­â­ | â­â­â­â­â­ |
| `all-MiniLM-L6-v2` | HuggingFace | 384 | â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |

### 7.3. Reranker Modeli

| Model | Provider | TÃ¼rkÃ§e DesteÄŸi | HÄ±z | DoÄŸruluk | Maliyet |
|-------|----------|----------------|-----|----------|---------|
| Alibaba Reranker | Alibaba | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |

---

## 8. Optimizasyonlar ve Best Practices

### 8.1. Caching Stratejileri

**Topic Classification Cache:**
- 7 gÃ¼nlÃ¼k TTL
- Query hash bazlÄ±
- %40-60 maliyet tasarrufu

**QA Similarity Cache:**
- 30 gÃ¼nlÃ¼k TTL
- Question hash bazlÄ±
- Embedding model bazlÄ± cache

### 8.2. Batch Processing

**Embedding Batch:**
- 25 metin tek seferde iÅŸlenir
- %75-80 maliyet azalmasÄ±
- HÄ±z artÄ±ÅŸÄ±

### 8.3. Direct QA Match

**Optimizasyon:**
- Similarity > 0.90 â†’ Direkt cevap
- LLM generation atlanÄ±r
- %80-90 sÃ¼re tasarrufu

### 8.4. Async RAG

**KullanÄ±m:**
- Uzun sorgular (>150 karakter)
- Semantic chunking aktifse
- Background task ile non-blocking

---

## 9. Hata YÃ¶netimi ve Fallback

### 9.1. Model Fallback

**SÄ±ralama:**
1. Request model
2. Session model
3. VarsayÄ±lan model (Groq)
4. OpenRouter (Ã¼cretsiz)
5. HuggingFace (Ã¼cretsiz)

### 9.2. Embedding Fallback

**SÄ±ralama:**
1. Session embedding model
2. VarsayÄ±lan (Alibaba `text-embedding-v4`)
3. HuggingFace (Ã¼cretsiz)

### 9.3. Reranker Fallback

**Durum:**
- Reranker baÅŸarÄ±sÄ±z olursa â†’ Original chunks kullanÄ±lÄ±r
- Reranking atlanÄ±r, retrieval sonuÃ§larÄ± direkt kullanÄ±lÄ±r

### 9.4. Low Score Rejection

**MantÄ±k:**
```python
# hybrid_rag_query.py - Line 761
if max_score < min_score_threshold:
    return "Bu bilgi ders dÃ¶kÃ¼manlarÄ±nda bulunamamÄ±ÅŸtÄ±r."
```

**Threshold:**
- VarsayÄ±lan: 0.4 (40%)
- Session RAG settings'den alÄ±nabilir
- DÃ¼ÅŸÃ¼k skorlu kaynaklar reddedilir

---

## 10. SonuÃ§ ve Ã–neriler

### 10.1. Model SeÃ§im Ã–nerileri

**HÄ±z Ã–ncelikli:**
- LLM: Groq `llama-3.1-8b-instant`
- Embedding: Alibaba `text-embedding-v4`
- Reranker: Alibaba Reranker

**TÃ¼rkÃ§e Ã–ncelikli:**
- LLM: Alibaba `qwen-max` veya `qwen-turbo`
- Embedding: Alibaba `text-embedding-v4`
- Reranker: Alibaba Reranker

**Maliyet Ã–ncelikli:**
- LLM: OpenRouter Ã¼cretsiz modeller
- Embedding: HuggingFace Ã¼cretsiz modeller
- Reranker: Alibaba Reranker (dÃ¼ÅŸÃ¼k maliyet)

### 10.2. Best Practices

1. **Embedding Model Uyumu:**
   - Session embedding model'i collection boyutuna uygun olmalÄ±
   - Model deÄŸiÅŸikliÄŸinde collection yeniden oluÅŸturulmalÄ±

2. **Reranking KullanÄ±mÄ±:**
   - Uzun sorgular iÃ§in aktif edilmeli
   - Kalite artÄ±ÅŸÄ± saÄŸlar

3. **Direct QA Match:**
   - YÃ¼ksek similarity (>0.90) iÃ§in direkt cevap
   - HÄ±z ve maliyet tasarrufu

4. **Async RAG:**
   - Uzun sorgular iÃ§in kullanÄ±lmalÄ±
   - KullanÄ±cÄ± deneyimi kesintisiz

5. **Caching:**
   - Topic classification cache aktif
   - QA similarity cache aktif
   - Maliyet ve hÄ±z optimizasyonu

---

**HazÄ±rlanma Tarihi**: 2025-12-05
**Durum**: Student Chat Sistemi DetaylÄ± DokÃ¼mantasyonu
**Versiyon**: 1.0


