# EBARS Technical System Specification

## Executive Summary

This document provides complete technical specifications for the EBARS (Emoji-Based Adaptive Response System) including system architecture, API documentation, database schema, performance benchmarks, and deployment requirements. This specification supports academic research reproducibility and system implementation.

## Table of Contents

1. [System Architecture](#1-system-architecture)
2. [Component Documentation](#2-component-documentation)
3. [API Reference](#3-api-reference)
4. [Database Schema](#4-database-schema)
5. [Performance Benchmarks](#5-performance-benchmarks)
6. [System Requirements](#6-system-requirements)
7. [Deployment Guide](#7-deployment-guide)
8. [Security Considerations](#8-security-considerations)

## 1. System Architecture

### 1.1 High-Level Architecture

The EBARS system follows a microservices architecture with the following core components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend UI   â”‚â”€â”€â”€â–¶â”‚   API Gateway   â”‚â”€â”€â”€â–¶â”‚  EBARS Service  â”‚
â”‚   (React/JS)    â”‚    â”‚   (FastAPI)     â”‚    â”‚   (Python)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                        â”‚
                              â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Document Proc. â”‚    â”‚   Database      â”‚    â”‚  Model Inferenceâ”‚
â”‚   Service       â”‚    â”‚   (SQLite)      â”‚    â”‚    Service      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Component Interaction Flow

#### 1.2.1 Student Interaction Flow

```mermaid
sequenceDiagram
    participant S as Student
    participant F as Frontend
    participant G as Gateway
    participant E as EBARS
    participant D as Database

    S->>F: Submit question
    F->>G: POST /hybrid-rag/query
    G->>E: Get current state
    E->>D: Retrieve comprehension score
    D-->>E: Return current state
    E-->>G: Adaptive prompt parameters
    G->>F: Generated response
    F->>S: Display adaptive answer

    S->>F: Provide emoji feedback
    F->>G: POST /ebars/feedback
    G->>E: Process feedback
    E->>D: Update scores & difficulty
    D-->>E: Confirm update
    E-->>G: New state
    G-->>F: Success confirmation
```

#### 1.2.2 Simulation Flow

```mermaid
sequenceDiagram
    participant Sim as Simulation Engine
    participant Agent as Agent Profile
    participant API as EBARS API
    participant DB as Database

    loop For each turn (1-20)
        Sim->>Agent: Generate question
        Agent->>API: Submit query
        API->>DB: Get current state
        DB-->>API: Return state
        API-->>Agent: Adaptive response
        Agent->>Agent: Determine emoji feedback
        Agent->>API: Submit emoji feedback
        API->>DB: Update comprehension score
        DB-->>API: Confirm update
        API-->>Agent: New state
        Agent->>Sim: Log interaction data
    end
```

### 1.3 Data Flow Architecture

#### 1.3.1 Request Processing Pipeline

1. **Input Validation**: Schema validation, sanitization, authentication
2. **State Retrieval**: Current user comprehension score and difficulty level
3. **Adaptive Processing**: Prompt parameter generation based on difficulty
4. **Response Generation**: LLM inference with adaptive parameters
5. **Feedback Processing**: Emoji-based score adjustment and level transitions
6. **State Persistence**: Database updates and logging
7. **Response Formatting**: JSON response with metadata

#### 1.3.2 Data Storage Strategy

- **Operational Data**: Real-time user states, sessions, interactions
- **Analytics Data**: Aggregated metrics, performance statistics
- **Simulation Data**: Agent profiles, turn-based interaction logs
- **Configuration Data**: System parameters, feature flags, model settings

## 2. Component Documentation

### 2.1 EBARS Core Service

**Location**: [`services/aprag_service/ebars/`](../services/aprag_service/ebars/)

#### 2.1.1 Core Modules

**Router Module** ([`router.py`](../services/aprag_service/ebars/router.py))

- FastAPI endpoints for EBARS functionality
- Request/response model definitions
- Error handling and validation
- Authentication and authorization

**Feedback Handler** ([`feedback_handler.py`](../services/aprag_service/ebars/feedback_handler.py))

- Emoji feedback processing logic
- Score calculation and adjustment
- State management and persistence
- Adaptive prompt generation

**Score Calculator** ([`score_calculator.py`](../services/aprag_service/ebars/score_calculator.py))

- Comprehension score algorithms
- Difficulty level mapping
- Statistical tracking and metrics
- Threshold management

**Prompt Adapter** ([`prompt_adapter.py`](../services/aprag_service/ebars/prompt_adapter.py))

- Difficulty-based prompt modification
- Parameter template management
- Content complexity adjustment
- Language adaptation

#### 2.1.2 Configuration Parameters

```python
# EBARS Configuration
EBARS_CONFIG = {
    "score_adjustments": {
        "thumbs_up": 2.5,
        "happy": 1.8,
        "neutral": 0.2,
        "negative": -1.5
    },
    "difficulty_thresholds": {
        "very_struggling": (0, 30),
        "struggling": (31, 45),
        "normal": (46, 70),
        "good": (71, 84),
        "excellent": (85, 100)
    },
    "adaptation_parameters": {
        "min_turns_before_change": 2,
        "hysteresis_buffer": 2.0,
        "momentum_factor": 0.1
    }
}
```

### 2.2 Simulation Engine

**Location**: [`simulasyon_testleri/ebars_simulation_working.py`](../ebars_simulation_working.py)

#### 2.2.1 Agent Profile Implementation

**EBARSAgent Class Architecture**:

```python
class EBARSAgent:
    def __init__(self, agent_id, profile_type, api_base_url):
        self.agent_id = agent_id
        self.profile = self.get_profile_config(profile_type)
        self.interaction_history = []
        self.current_state = {}

    def get_profile_config(self, profile_type):
        profiles = {
            'struggling': {
                'initial_score_range': (25, 35),
                'learning_rate': (1.2, 1.8),
                'emoji_probabilities': {
                    'âŒ': 0.70, 'ðŸ˜': 0.20,
                    'ðŸ˜Š': 0.08, 'ðŸ‘': 0.02
                },
                'noise_factor': 0.3
            },
            'fast_learner': {
                'initial_score_range': (50, 65),
                'learning_rate': (2.5, 3.2),
                'emoji_probabilities': {
                    'ðŸ‘': 0.60, 'ðŸ˜Š': 0.20,
                    'ðŸ˜': 0.15, 'âŒ': 0.05
                },
                'noise_factor': 0.15
            },
            'variable': {
                'initial_score_range': (40, 50),
                'learning_rate': (1.5, 2.2),
                'emoji_probabilities': {
                    'ðŸ‘': 0.25, 'ðŸ˜Š': 0.25,
                    'ðŸ˜': 0.25, 'âŒ': 0.25
                },
                'noise_factor': 0.4,
                'oscillation_factor': 0.2
            }
        }
        return profiles[profile_type]
```

#### 2.2.2 Simulation Parameters

**Standard Configuration**:

- **Duration**: 20 turns per agent
- **Agents**: 3 (one per profile type)
- **Replication**: 10 independent runs
- **Data Output**: CSV format with comprehensive metrics

**Extended Configuration**:

- **Duration**: 50 turns per agent
- **Noise Levels**: Multiple variance parameters
- **Missing Data**: Simulated incomplete feedback scenarios
- **Robustness Testing**: Parameter sensitivity analysis

### 2.3 Analysis Framework

**Location**: [`simulasyon_testleri/analyze_results.py`](../analyze_results.py)

#### 2.3.1 Statistical Analysis Components

**EBARSResultsAnalyzer Class**:

- Adaptation effectiveness metrics calculation
- Score convergence analysis
- System responsiveness measurement
- Stability and hysteresis analysis
- Comparative statistical testing
- Academic reporting generation

**Key Analysis Methods**:

```python
def calculate_adaptation_effectiveness(self) -> Dict[str, AdaptationMetrics]:
    """Calculate comprehensive adaptation effectiveness metrics"""

def perform_statistical_comparisons(self) -> Dict[str, List[StatisticalResult]]:
    """Perform statistical comparisons between agent profiles"""

def analyze_learning_curves(self) -> Dict[str, Dict[str, Any]]:
    """Analyze and characterize learning curve patterns"""
```

#### 2.3.2 Statistical Metrics

**Adaptation Metrics**:

- Convergence Rate: Exponential fit parameter
- Stability Index: Inverse variance of final scores
- Adaptation Speed: Mean absolute score delta
- Learning Efficiency: Improvement per unit time
- Hysteresis Index: Resistance to oscillation

**Comparative Statistics**:

- Cohen's d for effect sizes
- Mann-Whitney U for non-parametric comparisons
- One-way ANOVA for group differences
- Confidence intervals for all estimates

### 2.4 Visualization System

**Location**: [`simulasyon_testleri/visualization.py`](../visualization.py)

#### 2.4.1 Visualization Components

**EBARSVisualizer Class Features**:

- Comprehensive score evolution plots
- Difficulty level transition analysis
- Performance comparison charts
- Score delta (adaptation speed) visualization
- Response time analysis plots

**Output Formats**:

- High-resolution PNG (300 DPI)
- Vector SVG for scalability
- Publication-ready PDF
- Interactive HTML reports

#### 2.4.2 Academic Quality Standards

**Plot Specifications**:

- Professional color schemes with accessibility considerations
- Bilingual label support (English/Turkish)
- Statistical annotations and trend lines
- Error bars and confidence intervals
- Publication-ready formatting (12pt fonts, clear legends)

## 3. API Reference

### 3.1 EBARS Core Endpoints

#### 3.1.1 Feedback Processing

**Endpoint**: `POST /api/aprag/ebars/feedback`

**Request Schema**:

```json
{
  "user_id": "string",
  "session_id": "string",
  "emoji": "string",
  "interaction_id": "integer (optional)",
  "query_text": "string (optional)"
}
```

**Response Schema**:

```json
{
  "success": true,
  "new_score": 75.5,
  "new_difficulty": "good",
  "score_delta": 2.5,
  "difficulty_changed": true,
  "previous_difficulty": "normal"
}
```

**Emoji Values**: `ðŸ‘`, `ðŸ˜Š`, `ðŸ˜`, `âŒ`

#### 3.1.2 State Retrieval

**Endpoint**: `GET /api/aprag/ebars/state/{user_id}/{session_id}`

**Response Schema**:

```json
{
  "comprehension_score": 75.5,
  "difficulty_level": "good",
  "prompt_parameters": {
    "complexity_level": "intermediate",
    "example_count": 2,
    "detail_level": "moderate"
  },
  "statistics": {
    "total_interactions": 45,
    "feedback_count": 38,
    "level_changes": 3,
    "session_duration_minutes": 23
  },
  "adaptive_prompt": "Based on your good performance..."
}
```

#### 3.1.3 Advanced State Retrieval with Context

**Endpoint**: `POST /api/aprag/ebars/state/{user_id}/{session_id}`

**Request Schema**:

```json
{
  "query": "string (optional)",
  "context": "string (optional)"
}
```

**Response**: Same as GET endpoint plus:

```json
{
  "complete_prompt": "Complete adaptive prompt with context..."
}
```

### 3.2 Administrative Endpoints

#### 3.2.1 Score Management

**Reset Score**: `POST /api/aprag/ebars/score/reset/{user_id}/{session_id}`

- Resets comprehension score to 50.0
- Returns to 'normal' difficulty level
- Clears consecutive feedback counters

**Get Score**: `GET /api/aprag/ebars/score/{user_id}/{session_id}`

- Returns current score and difficulty level
- Includes statistical summary

#### 3.2.2 Initial Cognitive Testing

**Check Test Status**: `GET /api/aprag/ebars/check-initial-test/{user_id}/{session_id}`

**Generate Test**: `POST /api/aprag/ebars/generate-initial-test/{user_id}/{session_id}`

**Submit Test**: `POST /api/aprag/ebars/submit-initial-test`

**Test Flow Architecture**:

1. Check if student needs initial cognitive test
2. Generate 5 questions from session content
3. Evaluate student responses (multiple choice)
4. Present leveled answer examples (5 difficulty levels)
5. Set initial comprehension score based on preferences

### 3.3 Error Handling

#### 3.3.1 Standard Error Responses

**HTTP Status Codes**:

- `200 OK`: Successful operation
- `400 Bad Request`: Invalid input parameters
- `403 Forbidden`: EBARS feature disabled for session
- `404 Not Found`: User/session not found
- `500 Internal Server Error`: System error

**Error Response Format**:

```json
{
  "success": false,
  "error": "Detailed error message",
  "error_code": "EBARS_ERROR_CODE",
  "timestamp": "2025-12-06T13:30:00Z"
}
```

#### 3.3.2 Rate Limiting

**Default Limits**:

- Feedback endpoint: 60 requests per minute per user
- State endpoint: 120 requests per minute per user
- Test endpoints: 10 requests per minute per user

## 4. Database Schema

### 4.1 Core Tables

#### 4.1.1 Student Comprehension Scores

**Table**: `student_comprehension_scores`

```sql
CREATE TABLE student_comprehension_scores (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id TEXT NOT NULL,
    session_id TEXT NOT NULL,
    comprehension_score REAL DEFAULT 50.0,
    current_difficulty_level TEXT DEFAULT 'normal',
    consecutive_positive_count INTEGER DEFAULT 0,
    consecutive_negative_count INTEGER DEFAULT 0,
    has_completed_initial_test BOOLEAN DEFAULT 0,
    initial_test_score REAL,
    initial_test_completed_at DATETIME,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(user_id, session_id)
);
```

**Indexes**:

```sql
CREATE INDEX idx_user_session ON student_comprehension_scores(user_id, session_id);
CREATE INDEX idx_last_updated ON student_comprehension_scores(last_updated);
CREATE INDEX idx_difficulty_level ON student_comprehension_scores(current_difficulty_level);
```

#### 4.1.2 Emoji Feedback History

**Table**: `emoji_feedback_history`

```sql
CREATE TABLE emoji_feedback_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id TEXT NOT NULL,
    session_id TEXT NOT NULL,
    interaction_id INTEGER,
    emoji TEXT NOT NULL,
    old_score REAL NOT NULL,
    new_score REAL NOT NULL,
    score_delta REAL NOT NULL,
    old_difficulty TEXT,
    new_difficulty TEXT,
    difficulty_changed BOOLEAN DEFAULT 0,
    query_text TEXT,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

**Indexes**:

```sql
CREATE INDEX idx_feedback_user_session ON emoji_feedback_history(user_id, session_id);
CREATE INDEX idx_feedback_created_at ON emoji_feedback_history(created_at);
CREATE INDEX idx_feedback_emoji ON emoji_feedback_history(emoji);
```

#### 4.1.3 Initial Cognitive Tests

**Table**: `initial_cognitive_tests`

```sql
CREATE TABLE initial_cognitive_tests (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id TEXT NOT NULL,
    session_id TEXT NOT NULL,
    questions TEXT NOT NULL,  -- JSON array of questions
    total_questions INTEGER NOT NULL,
    correct_answers INTEGER DEFAULT 0,
    total_score REAL DEFAULT 0.0,
    test_attempt INTEGER DEFAULT 1,
    answer_preferences TEXT,  -- JSON array of preferences
    started_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    completed_at DATETIME,
    UNIQUE(user_id, session_id)
);
```

### 4.2 Data Relationships

#### 4.2.1 Foreign Key Constraints

```sql
-- Link feedback to comprehension scores
ALTER TABLE emoji_feedback_history
ADD CONSTRAINT fk_feedback_scores
FOREIGN KEY (user_id, session_id)
REFERENCES student_comprehension_scores(user_id, session_id);

-- Link tests to comprehension scores
ALTER TABLE initial_cognitive_tests
ADD CONSTRAINT fk_tests_scores
FOREIGN KEY (user_id, session_id)
REFERENCES student_comprehension_scores(user_id, session_id);
```

#### 4.2.2 Data Integrity Constraints

```sql
-- Score bounds checking
ALTER TABLE student_comprehension_scores
ADD CONSTRAINT chk_score_range
CHECK (comprehension_score >= 0 AND comprehension_score <= 100);

-- Valid difficulty levels
ALTER TABLE student_comprehension_scores
ADD CONSTRAINT chk_difficulty_level
CHECK (current_difficulty_level IN (
    'very_struggling', 'struggling', 'normal', 'good', 'excellent'
));

-- Valid emoji values
ALTER TABLE emoji_feedback_history
ADD CONSTRAINT chk_emoji_values
CHECK (emoji IN ('ðŸ‘', 'ðŸ˜Š', 'ðŸ˜', 'âŒ'));
```

### 4.3 Performance Optimization

#### 4.3.1 Query Optimization Strategies

**Common Queries Optimized**:

```sql
-- Get current user state (most frequent)
SELECT comprehension_score, current_difficulty_level
FROM student_comprehension_scores
WHERE user_id = ? AND session_id = ?;

-- Get recent feedback history
SELECT emoji, score_delta, created_at
FROM emoji_feedback_history
WHERE user_id = ? AND session_id = ?
ORDER BY created_at DESC LIMIT 10;

-- Aggregate statistics
SELECT
    AVG(comprehension_score) as avg_score,
    COUNT(*) as total_users,
    current_difficulty_level
FROM student_comprehension_scores
WHERE session_id = ?
GROUP BY current_difficulty_level;
```

#### 4.3.2 Maintenance Procedures

**Regular Maintenance**:

```sql
-- Cleanup old feedback history (older than 30 days)
DELETE FROM emoji_feedback_history
WHERE created_at < datetime('now', '-30 days');

-- Update statistics
ANALYZE;

-- Vacuum database
VACUUM;
```

## 5. Performance Benchmarks

### 5.1 Response Time Benchmarks

#### 5.1.1 API Endpoint Performance

**Target Response Times**:

- Feedback processing: < 100ms (95th percentile)
- State retrieval: < 50ms (95th percentile)
- Initial test generation: < 2000ms (95th percentile)
- Score calculations: < 10ms (99th percentile)

**Load Testing Results** (1000 concurrent users):

```
Endpoint                    | Avg Response | 95th % | 99th %
---------------------------|--------------|--------|--------
POST /ebars/feedback       | 45ms         | 87ms   | 145ms
GET /ebars/state          | 23ms         | 41ms   | 78ms
POST /generate-test       | 1234ms       | 1876ms | 2456ms
GET /score               | 18ms         | 34ms   | 67ms
```

#### 5.1.2 Database Performance

**Query Performance Benchmarks**:

```
Query Type                 | Avg Time | Operations/sec
--------------------------|----------|---------------
Score lookup             | 2.3ms    | 4,348
Score update             | 4.7ms    | 2,127
Feedback insert          | 3.1ms    | 3,226
History retrieval        | 5.8ms    | 1,724
Aggregate statistics     | 45.2ms   | 221
```

### 5.2 Simulation Performance

#### 5.2.1 Simulation Execution Times

**Standard Configuration** (3 agents, 20 turns):

- **Simulation Runtime**: 45-60 seconds
- **Data Generation**: 60 records per simulation
- **Memory Usage**: 15-25 MB peak
- **CPU Utilization**: 5-15% average

**Extended Configuration** (3 agents, 50 turns):

- **Simulation Runtime**: 180-240 seconds
- **Data Generation**: 150 records per simulation
- **Memory Usage**: 35-55 MB peak
- **CPU Utilization**: 10-25% average

#### 5.2.2 Analysis Performance

**Statistical Analysis Benchmarks**:

```
Analysis Component           | Runtime | Memory Usage
----------------------------|---------|-------------
Adaptation Effectiveness    | 2.3s    | 8 MB
Score Convergence          | 1.8s    | 6 MB
Statistical Comparisons    | 4.5s    | 12 MB
Correlation Analysis       | 1.2s    | 4 MB
Learning Curves           | 3.7s    | 10 MB
Complete Analysis         | 18.2s   | 45 MB
```

**Visualization Generation**:

```
Visualization Type         | Generation Time | File Size
--------------------------|-----------------|----------
Score Evolution           | 3.2s           | 2.1 MB (PNG)
Difficulty Transitions    | 2.8s           | 1.8 MB (PNG)
Performance Comparison    | 2.1s           | 1.5 MB (PNG)
Score Delta Analysis      | 2.5s           | 1.9 MB (PNG)
Response Time Analysis    | 1.9s           | 1.3 MB (PNG)
```

### 5.3 Scalability Analysis

#### 5.3.1 Concurrent User Capacity

**Single Instance Limits**:

- **Maximum Concurrent Users**: 500 active sessions
- **Database Connection Pool**: 20 connections
- **Memory per Session**: ~2-5 MB
- **CPU per Request**: ~5-15ms

**Scaling Strategies**:

- **Horizontal Scaling**: Load balancer with multiple instances
- **Database Scaling**: Read replicas for state queries
- **Caching**: Redis for frequent state lookups
- **CDN**: Static content and visualization serving

#### 5.3.2 Data Volume Handling

**Storage Growth Estimates**:

```
Users    | Sessions/User | Interactions | Storage/Month
---------|---------------|--------------|-------------
100      | 5            | 2,000        | 25 MB
1,000    | 10           | 50,000       | 500 MB
10,000   | 15           | 1,500,000    | 12 GB
100,000  | 20           | 40,000,000   | 250 GB
```

**Archive Strategy**:

- Active data: Last 30 days in primary database
- Historical data: Compressed archive storage
- Analytics: Aggregated summaries retained indefinitely
- Raw logs: 90-day retention policy

## 6. System Requirements

### 6.1 Hardware Requirements

#### 6.1.1 Minimum Requirements

**Development Environment**:

- **CPU**: 2 cores, 2.0 GHz
- **RAM**: 4 GB
- **Storage**: 10 GB available space
- **Network**: 10 Mbps internet connection

**Production Environment**:

- **CPU**: 4 cores, 2.5 GHz
- **RAM**: 8 GB
- **Storage**: 50 GB SSD
- **Network**: 100 Mbps dedicated bandwidth

#### 6.1.2 Recommended Requirements

**Development Environment**:

- **CPU**: 4 cores, 3.0 GHz
- **RAM**: 16 GB
- **Storage**: 25 GB SSD
- **GPU**: Optional for ML model inference acceleration

**Production Environment**:

- **CPU**: 8 cores, 3.5 GHz
- **RAM**: 32 GB
- **Storage**: 200 GB NVMe SSD
- **GPU**: NVIDIA RTX 4060 or equivalent for model inference
- **Network**: 1 Gbps with load balancing

### 6.2 Software Requirements

#### 6.2.1 Core Dependencies

**Runtime Environment**:

- **Python**: 3.8+ (recommended: 3.11)
- **Node.js**: 16+ for frontend components
- **SQLite**: 3.35+ for database
- **Redis**: 6.0+ for caching (optional)

**Python Dependencies**:

```requirements.txt
fastapi>=0.104.1
uvicorn>=0.24.0
pydantic>=2.5.0
pandas>=2.1.0
numpy>=1.24.0
scipy>=1.11.0
matplotlib>=3.7.0
seaborn>=0.12.0
scikit-learn>=1.3.0
requests>=2.31.0
psutil>=5.9.0
```

#### 6.2.2 Development Tools

**Required Development Tools**:

- **Git**: Version control
- **Docker**: Containerization (optional)
- **pytest**: Testing framework
- **black**: Code formatting
- **mypy**: Type checking
- **sphinx**: Documentation generation

**IDE Recommendations**:

- **Visual Studio Code**: With Python and LaTeX extensions
- **PyCharm Professional**: Comprehensive Python IDE
- **Jupyter Lab**: For data analysis and experimentation

### 6.3 Environment Configuration

#### 6.3.1 Environment Variables

**Required Variables**:

```bash
# Database Configuration
DATABASE_PATH="/path/to/database.db"
APRAG_DB_PATH="/path/to/aprag_database.db"

# API Configuration
API_GATEWAY_URL="http://localhost:8000"
MODEL_INFERENCE_URL="http://localhost:8002"
DOCUMENT_PROCESSING_URL="http://localhost:8080"

# EBARS Configuration
EBARS_ENABLED="true"
EBARS_LOG_LEVEL="INFO"
EBARS_MAX_SESSIONS="1000"

# Security
SECRET_KEY="your-secret-key-here"
API_KEY="your-api-key-here"
```

**Optional Variables**:

```bash
# Performance Tuning
DB_CONNECTION_POOL_SIZE="20"
REQUEST_TIMEOUT_SECONDS="30"
MAX_CONCURRENT_REQUESTS="100"

# Feature Flags
ENABLE_INITIAL_TESTING="true"
ENABLE_LEVEL_PREVIEW="true"
ENABLE_STATISTICS_API="false"

# Monitoring
ENABLE_METRICS="true"
METRICS_PORT="9090"
LOG_FILE_PATH="/var/log/ebars.log"
```

#### 6.3.2 Configuration Files

**Main Configuration** (`config/ebars_config.yml`):

```yaml
ebars:
  score_adjustments:
    thumbs_up: 2.5
    happy: 1.8
    neutral: 0.2
    negative: -1.5

  difficulty_thresholds:
    very_struggling: [0, 30]
    struggling: [31, 45]
    normal: [46, 70]
    good: [71, 84]
    excellent: [85, 100]

  adaptation:
    min_turns_before_change: 2
    hysteresis_buffer: 2.0
    momentum_factor: 0.1
    max_consecutive_same_feedback: 5

simulation:
  default_turns: 20
  default_agents: 3
  output_format: "csv"
  include_metadata: true

analysis:
  confidence_level: 0.95
  effect_size_threshold: 0.5
  statistical_power: 0.80
  multiple_comparison_correction: "bonferroni"
```

### 6.4 Network Requirements

#### 6.4.1 Port Configuration

**Required Ports**:

- **8007**: EBARS API service
- **8000**: API Gateway
- **8002**: Model inference service
- **8080**: Document processing service
- **3000**: Frontend development server (development only)

**Optional Ports**:

- **6379**: Redis cache server
- **9090**: Metrics/monitoring endpoint
- **5432**: PostgreSQL (if upgrading from SQLite)

#### 6.4.2 External Dependencies

**Required External Services**:

- **LLM Provider**: OpenAI API, Anthropic Claude, or local model server
- **Email Service**: For notifications (optional)
- **File Storage**: S3-compatible storage for large datasets (optional)

**Network Security**:

- HTTPS/TLS encryption for all external API calls
- API key authentication for model inference services
- Rate limiting for all public endpoints
- CORS policy configuration for frontend integration

## 7. Deployment Guide

### 7.1 Development Deployment

#### 7.1.1 Local Development Setup

**Quick Start**:

```bash
# Clone repository
git clone <repository-url>
cd ebars-system

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your configuration

# Initialize database
python scripts/init_database.py

# Start development server
uvicorn main:app --reload --port 8007
```

**Development Scripts**:

```bash
# Run simulation
cd simulasyon_testleri
python ebars_simulation_working.py

# Generate analysis
python analyze_results.py ebars_simulation_results_*.csv

# Create visualizations
python visualization.py ebars_simulation_results_*.csv

# Run tests
python test_complete_system.py
```

#### 7.1.2 Docker Development Environment

**Docker Compose Configuration** (`docker-compose.dev.yml`):

```yaml
version: "3.8"

services:
  ebars-api:
    build:
      context: .
      dockerfile: Dockerfile.dev
    ports:
      - "8007:8007"
    environment:
      - DATABASE_PATH=/app/data/ebars.db
      - ENVIRONMENT=development
    volumes:
      - ./data:/app/data
      - .:/app
    depends_on:
      - redis-cache

  redis-cache:
    image: redis:6.2-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data

volumes:
  redis-data:
```

**Development Commands**:

```bash
# Start development environment
docker-compose -f docker-compose.dev.yml up -d

# View logs
docker-compose -f docker-compose.dev.yml logs -f ebars-api

# Run simulation inside container
docker-compose exec ebars-api python simulasyon_testleri/ebars_simulation_working.py

# Stop environment
docker-compose -f docker-compose.dev.yml down
```

### 7.2 Production Deployment

#### 7.2.1 Production Configuration

**Production Environment Variables**:

```bash
# Production Database
DATABASE_PATH="/opt/ebars/data/production.db"
DB_BACKUP_PATH="/opt/ebars/backups"

# Security
SECRET_KEY="production-secret-key-256-bits"
ALLOWED_HOSTS="yourdomain.com,api.yourdomain.com"
CORS_ORIGINS="https://yourdomain.com"

# Performance
WORKERS=4
MAX_CONNECTIONS=100
REQUEST_TIMEOUT=30

# Monitoring
LOG_LEVEL="WARNING"
ENABLE_METRICS="true"
SENTRY_DSN="https://your-sentry-dsn"
```

**Production Docker Compose** (`docker-compose.prod.yml`):

```yaml
version: "3.8"

services:
  ebars-api:
    image: ebars-api:latest
    restart: unless-stopped
    ports:
      - "8007:8007"
    environment:
      - DATABASE_PATH=/app/data/production.db
      - WORKERS=4
      - LOG_LEVEL=WARNING
    volumes:
      - ebars-data:/app/data
      - ebars-logs:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8007/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  nginx:
    image: nginx:alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/ssl
    depends_on:
      - ebars-api

volumes:
  ebars-data:
  ebars-logs:
```

#### 7.2.2 Load Balancing and High Availability

**Nginx Configuration** (`nginx.conf`):

```nginx
upstream ebars_backend {
    server ebars-api-1:8007;
    server ebars-api-2:8007;
    server ebars-api-3:8007;

    # Health checks
    keepalive 32;
}

server {
    listen 80;
    server_name api.yourdomain.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name api.yourdomain.com;

    ssl_certificate /etc/ssl/fullchain.pem;
    ssl_certificate_key /etc/ssl/privkey.pem;

    location /api/aprag/ebars/ {
        proxy_pass http://ebars_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Timeouts
        proxy_connect_timeout 5s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;

        # Rate limiting
        limit_req zone=api burst=20 nodelay;
    }

    location /health {
        proxy_pass http://ebars_backend;
        access_log off;
    }
}

# Rate limiting zones
http {
    limit_req_zone $binary_remote_addr zone=api:10m rate=60r/m;
}
```

### 7.3 Monitoring and Maintenance

#### 7.3.1 Health Checks

**Health Check Endpoint** (`/health`):

```json
{
  "status": "healthy",
  "timestamp": "2025-12-06T13:30:00Z",
  "version": "1.0.0",
  "database": {
    "status": "connected",
    "response_time_ms": 3.2
  },
  "dependencies": {
    "model_inference": "available",
    "document_processing": "available"
  },
  "metrics": {
    "active_sessions": 45,
    "requests_per_minute": 1250,
    "average_response_time_ms": 67
  }
}
```

**Monitoring Checks**:

- Database connectivity and response time
- External API availability
- Memory usage and limits
- Active session count
- Request rate and response times
- Error rate monitoring

#### 7.3.2 Backup and Recovery

**Automated Backup Script**:

```bash
#!/bin/bash
# backup-ebars.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/opt/ebars/backups"
DB_PATH="/opt/ebars/data/production.db"

# Create backup
sqlite3 $DB_PATH ".backup $BACKUP_DIR/ebars_backup_$DATE.db"

# Compress backup
gzip "$BACKUP_DIR/ebars_backup_$DATE.db"

# Remove backups older than 30 days
find $BACKUP_DIR -name "ebars_backup_*.db.gz" -mtime +30 -delete

# Verify backup integrity
gunzip -c "$BACKUP_DIR/ebars_backup_$DATE.db.gz" | sqlite3 :memory: ".schema" > /dev/null

if [ $? -eq 0 ]; then
    echo "Backup successful: ebars_backup_$DATE.db.gz"
else
    echo "Backup verification failed!" >&2
    exit 1
fi
```

**Recovery Procedure**:

```bash
#!/bin/bash
# restore-ebars.sh

BACKUP_FILE=$1
DB_PATH="/opt/ebars/data/production.db"

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file.db.gz>"
    exit 1
fi

# Stop services
docker-compose stop ebars-api

# Backup current database
cp "$DB_PATH" "$DB_PATH.pre-restore.$(date +%Y%m%d_%H%M%S)"

# Restore from backup
gunzip -c "$BACKUP_FILE" > "$DB_PATH"

# Start services
docker-compose start ebars-api

echo "Database restored from $BACKUP_FILE"
```

## 8. Security Considerations

### 8.1 Authentication and Authorization

#### 8.1.1 API Security

**Authentication Methods**:

- API Key authentication for service-to-service calls
- JWT tokens for user sessions
- OAuth 2.0 integration support
- Rate limiting per API key/user

**Authorization Levels**:

- **Public**: Basic EBARS functionality (feedback, state)
- **Authenticated**: Full feature access
- **Admin**: System administration and analytics
- **Service**: Inter-service communication

#### 8.1.2 Data Protection

**Sensitive Data Handling**:

- User IDs hashed for privacy
- Session IDs include random components
- No PII stored in feedback logs
- Encryption at rest for production databases

**Data Retention Policies**:

- Active session data: Duration of session + 30 days
- Aggregated analytics: Indefinite retention (anonymized)
- Raw interaction logs: 90 days
- Error logs: 30 days

### 8.2 Input Validation and Sanitization

#### 8.2.1 Request Validation

**Schema Validation**:

```python
from pydantic import BaseModel, validator

class FeedbackRequest(BaseModel):
    user_id: str
    session_id: str
    emoji: str

    @validator('emoji')
    def validate_emoji(cls, v):
        allowed_emojis = ['ðŸ‘', 'ðŸ˜Š', 'ðŸ˜', 'âŒ']
        if v not in allowed_emojis:
            raise ValueError(f'Invalid emoji: {v}')
        return v

    @validator('user_id', 'session_id')
    def validate_ids(cls, v):
        if not v or len(v) > 100:
            raise ValueError('Invalid ID format')
        return v.strip()
```

**SQL Injection Prevention**:

- Parameterized queries exclusively
- No dynamic SQL construction
- Input sanitization at API boundaries
- ORM query building for complex operations

#### 8.2.2 Error Handling

**Security-Conscious Error Messages**:

- No sensitive data in error responses
- Generic error messages for security failures
- Detailed logging on server side
- Rate limiting for error-prone endpoints

### 8.3 Operational Security

#### 8.3.1 Deployment Security

**Container Security**:

- Non-root user execution
- Minimal base images (Alpine Linux)
- Regular security updates
- Network segmentation

**Infrastructure Security**:

- HTTPS/TLS encryption for all communications
- VPC/private network deployment
- Firewall rules limiting port access
- Regular security scanning

#### 8.3.2 Monitoring and Alerting

**Security Monitoring**:

- Failed authentication attempts
- Unusual request patterns
- Database access anomalies
- Resource usage spikes

**Alert Thresholds**:

- Failed authentication: >10 attempts per minute per IP
- Request rate: >1000 requests per minute per user
- Error rate: >5% of requests returning errors
- Database queries: >100ms average response time

---

## Conclusion

This technical specification provides comprehensive documentation of the EBARS system architecture, implementation details, and operational requirements. The specification supports academic research reproducibility while providing practical guidance for system implementation and deployment.

The modular design enables scalable deployment from development environments to production systems supporting thousands of concurrent users. Security considerations and performance benchmarks ensure the system meets enterprise deployment standards while maintaining academic research integrity.

**Document Version**: 1.0  
**Last Updated**: December 6, 2025  
**Authors**: EBARS Technical Team  
**Review Status**: Ready for Implementation

**Technical Contact**: ebars-technical@research.edu  
**Documentation Repository**: https://github.com/ebars-system/technical-docs
