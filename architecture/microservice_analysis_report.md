# Mikroservis Mimari Analizi ve Problem Tespiti

## Mevcut Servis Mimarisi

### 1. PDF Processing Service (Port: 8001)

**Lokasyon:** `services/pdf_processing_service/main.py`
**GerÃ§ek Rol:** PDF'leri Markdown'a dÃ¶nÃ¼ÅŸtÃ¼rme
**Endpoints:**

- `/process` - PDF dosyasÄ±nÄ± Markdown'a Ã§evirir
- `/health` - SaÄŸlÄ±k kontrolÃ¼

**Yetenekler:**

- Marker kÃ¼tÃ¼phanesi kullanarak PDFâ†’MD dÃ¶nÃ¼ÅŸÃ¼mÃ¼
- PyPDF2 fallback desteÄŸi
- Model cache manager ile optimize edilmiÅŸ model yÃ¼kleme
- **RAG yetenekleri: YOK**

### 2. Document Processing Service (Port: 8080)

**Lokasyon:** `services/document_processing_service/main.py`
**GerÃ§ek Rol:** TAM RAG PÄ°PELÄ°NE SERVÄ°SÄ°
**Endpoints:**

- `/process-and-store` - Metni chunk'lara ayÄ±rÄ±r ve embedding'ler oluÅŸturur
- `/query` - RAG sorgusu iÅŸler (ChromaDB + Model Inference entegrasyonu)
- `/health` - SaÄŸlÄ±k kontrolÃ¼

**Yetenekler:**

- Regex tabanlÄ± text chunking
- Model Inference Service'ten embedding'ler alÄ±r
- ChromaDB ile vektÃ¶r arama
- TÃ¼rkÃ§e RAG prompt'larÄ±
- Groq/Ollama modelleri ile text generation
- **BU SERVÄ°S RAG QUERY'LERÄ° Ä°ÅLEMELÄ°!**

### 3. Model Inference Service (Port: 8002)

**Lokasyon:** `services/model_inference_service/main.py`
**GerÃ§ek Rol:** LLM ve Embedding Model SaÄŸlayÄ±cÄ±
**Endpoints:**

- `/models/generate` - Text generation
- `/embed` - Embedding oluÅŸturma
- `/query` - **PROBLEM KAYNAÄI!**
- `/models/available` - Mevcut modeller

**Yetenekler:**

- Ollama ve Groq model desteÄŸi
- Nomic-embed-text ile embedding
- **HATA MESAJI BURADAN GELÄ°YOR:**

```python
# Line 327-328'de:
return RAGQueryResponse(
    answer="I'm a lightweight model inference service and don't have access to the full RAG pipeline. "
           "Please ensure you're connecting to the correct RAG service.",
    sources=[]
)
```

### 4. API Gateway (Port: 8080)

**Lokasyon:** `src/api/main_gateway.py`
**GerÃ§ek Rol:** Request Routing
**Routing Logic:**

- `/rag/query` â†’ `DOCUMENT_PROCESSOR_URL/query` âœ… DOÄRU
- `/documents/convert-document-to-markdown` â†’ `PDF_PROCESSOR_URL/process` âœ… DOÄRU
- `/documents/process-and-store` â†’ `DOCUMENT_PROCESSOR_URL/process-and-store` âœ… DOÄRU

## Problem Analizi

### Hata MesajÄ±nÄ±n KaynaÄŸÄ±

âŒ **"I'm a lightweight model inference service" hatasÄ± Model Inference Service'ten geliyor**

### Neden Bu Hata AlÄ±nÄ±yor?

#### Ä°htimal 1: YanlÄ±ÅŸ URL KonfigÃ¼rasyonu

API Gateway'de `DOCUMENT_PROCESSOR_URL` ortam deÄŸiÅŸkeni yanlÄ±ÅŸ ayarlanmÄ±ÅŸ olabilir:

**Deployment Config'de (`cloudbuild-api-gateway.yaml` line 53):**

```yaml
DOCUMENT_PROCESSOR_URL=https://doc-proc-service-awe3elsvra-ew.a.run.app
```

**Test'te gÃ¶rÃ¼len URL'ler:**

```python
API_GATEWAY_URL = "https://api-gateway-1051060211087.europe-west1.run.app"
```

URL format'larÄ± farklÄ±! Bu eski deployment URL'lerinin kullanÄ±lmakta olduÄŸunu gÃ¶steriyor.

#### Ä°htimal 2: Service Discovery Problemi

Document Processing Service deploy edilmemiÅŸ veya eriÅŸilemez durumda olabilir.

#### Ä°htimal 3: Cache Problemi

API Gateway eski URL'leri cache'lemiÅŸ olabilir.

## RAG Workflow HaritasÄ±

### DoÄŸru Workflow

```mermaid
graph TD
    A[Client] --> B[API Gateway :8080]
    B --> |PDF Upload| C[PDF Processing Service :8001]
    C --> |Markdown| B
    B --> |Process Documents| D[Document Processing Service :8080]
    D --> |Embeddings| E[Model Inference Service :8002]
    E --> |Vectors| D
    D --> |Store| F[ChromaDB]

    A --> |RAG Query| B
    B --> |Query| D
    D --> |Search| F
    F --> |Context| D
    D --> |Generate| E
    E --> |Response| D
    D --> |Answer| B
    B --> |Result| A
```

### Mevcut HatalÄ± Durum

```mermaid
graph TD
    A[Client] --> B[API Gateway]
    B --> |RAG Query| C[âŒ Model Inference Service]
    C --> |Error Message| B
    B --> |Error| A

    D[Document Processing Service] --> |Unused!| E[ChromaDB]
    D --> |Unused!| C
```

## Environment URL Analizi

### Deployment Config URL'leri

```yaml
PDF_PROCESSOR_URL=https://pdf-processor-awe3elsvra-ew.a.run.app
DOCUMENT_PROCESSOR_URL=https://doc-proc-service-awe3elsvra-ew.a.run.app
MODEL_INFERENCE_URL=https://model-inferencer-awe3elsvra-ew.a.run.app
```

### Test'te KullanÄ±lan URL'ler

```python
API_GATEWAY_URL = "https://api-gateway-1051060211087.europe-west1.run.app"
RAG_SERVICE_URL = "https://rag-service-1051060211087.europe-west1.run.app"
```

**Problem:** URL format'larÄ± tutarsÄ±z!

## Ã‡Ã¶zÃ¼m Ã–nerileri

### 1. URL KonfigÃ¼rasyonunu Kontrol Et

```bash
# API Gateway'de mevcut environment variable'larÄ± kontrol et
gcloud run services describe api-gateway --region=europe-west1 --format="export"
```

### 2. Document Processing Service Deployment'Ä±nÄ± DoÄŸrula

```bash
# Service'in Ã§alÄ±ÅŸÄ±r durumda olduÄŸunu kontrol et
curl https://doc-proc-service-awe3elsvra-ew.a.run.app/health
```

### 3. API Gateway Environment Variable'larÄ±nÄ± GÃ¼ncelle

```bash
gcloud run services update api-gateway \
  --region=europe-west1 \
  --update-env-vars DOCUMENT_PROCESSOR_URL=https://doc-proc-service-1051060211087.europe-west1.run.app
```

### 4. RAG Service URL'sini KaldÄ±r

API Gateway'de `RAG_SERVICE_URL` kullanÄ±lmÄ±yor, bunun yerine `DOCUMENT_PROCESSOR_URL` kullanÄ±lÄ±yor.

## Servis SorumluluklarÄ± Matrisi

| Servis              | PDFâ†’MD | Chunking | Embeddings       | Vector Store | RAG Query   | LLM Generate     |
| ------------------- | ------ | -------- | ---------------- | ------------ | ----------- | ---------------- |
| PDF Processing      | âœ…     | âŒ       | âŒ               | âŒ           | âŒ          | âŒ               |
| Document Processing | âŒ     | âœ…       | ğŸ”„ (calls Model) | âœ…           | âœ…          | ğŸ”„ (calls Model) |
| Model Inference     | âŒ     | âŒ       | âœ…               | âŒ           | âŒ          | âœ…               |
| API Gateway         | âŒ     | âŒ       | âŒ               | âŒ           | ğŸ”„ (routes) | âŒ               |

## Kritik Bulgular

1. **Document Processing Service gerÃ§ek RAG engine'i**
2. **Model Inference Service sadece model saÄŸlayÄ±cÄ±**
3. **API Gateway routing'i doÄŸru ama URL'ler yanlÄ±ÅŸ**
4. **Deployment'taki URL'ler test URL'leri ile tutarsÄ±z**
5. **Cache veya environment configuration problemi var**

Bu analiz, mikroservis mimarisinin doÄŸru tasarlandÄ±ÄŸÄ±nÄ± ama deployment configuration'da problem olduÄŸunu gÃ¶steriyor.
